<!doctype html><html lang=zh-tw dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[AI] 迴歸問題 | Rain Hu's Workspace</title><meta name=keywords content="AI"><meta name=description content="Regression problem"><meta name=author content="Rain Hu"><link rel=canonical href=https://intervalrain.github.io/><meta name=google-site-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0cefe5a1d95e3d0f0cce057d37c60cd238d1a4af825090f831a18f21671f621d.css integrity="sha256-DO/lodlePQ8MzgV9N8YM0jjRpK+CUJD4MaGPIWcfYh0=" rel="preload stylesheet" as=style><link rel=icon href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=16x16 href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=32x32 href=https://intervalrain.github.io/images/rain.png><link rel=apple-touch-icon href=https://intervalrain.github.io/images/rain.png><link rel=mask-icon href=https://intervalrain.github.io/images/rain.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-tw href=https://intervalrain.github.io/ai/4_3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script><script src=https://utteranc.es/client.js repo=intervalrain.github.io issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script><meta property="og:url" content="https://intervalrain.github.io/ai/4_3/"><meta property="og:site_name" content="Rain Hu's Workspace"><meta property="og:title" content="[AI] 迴歸問題"><meta property="og:description" content="Regression problem"><meta property="og:locale" content="zh-tw"><meta property="og:type" content="article"><meta property="article:section" content="ai"><meta property="article:published_time" content="2025-01-12T16:39:58+08:00"><meta property="article:modified_time" content="2025-01-12T16:39:58+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="[AI] 迴歸問題"><meta name=twitter:description content="Regression problem"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"[AI] 迴歸問題","item":"https://intervalrain.github.io/ai/4_3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[AI] 迴歸問題","name":"[AI] 迴歸問題","description":"Regression problem","keywords":["AI"],"articleBody":"認識波士頓住房價資料集 透過 tensorflow 引入資料集 波士頓住房價資料集是 1970 年代中期波士頓的郊區資料，包含犯罪率、當地財產稅等。 from tensorflow.keras.datasets import boston_housing (train_data, train_targets), (test_data, test_targets) = boston_housing.load_data() 與先前兩個範例最大的差別是，資料點明顯較少，共 404 + 102 = 506 筆。 print(train_data.shape) print(train_targets.shape) print(test_data.shape) print(test_targets.shape) \u003e (404, 13) (404,) (102, 13) (102,) 需注意，每個特徵都有不同的單位刻度 查看特徵分布 特徵值範圍分析:\n特徵 最小值 最大值 平均值 標準差 特徵意義 CRIM 0.006 88.976 3.614 8.602 城鎮人均犯罪率 ZN 0.000 100.000 11.364 23.322 佔地面積超過25000平方呎的住宅用地比例 INDUS 0.460 27.740 11.137 6.860 每個城鎮非零售商業用地的比例 CHAS 0.000 1.000 0.069 0.254 Charles River 虛擬變數 (1 if tract bounds river; 0 otherwise) NOX 0.385 0.871 0.555 0.116 一氧化氮濃度 RM 3.561 8.780 6.285 0.703 每棟住宅的平均房間數 AGE 2.900 100.000 68.575 28.149 1940年之前建成的自用房屋比例 DIS 1.130 12.126 3.795 2.106 到波士頓5個就業中心的加權距離 RAD 1.000 24.000 9.549 8.707 到高速公路的可達性指數 TAX 187.000 711.000 408.237 168.537 每10000美元的房產稅率 PTRATIO 12.600 22.000 18.456 2.165 城鎮師生比例 B 0.320 396.900 356.674 91.295 1000(Bk - 0.63)^2，其中Bk為城鎮中黑人的比例 LSTAT 1.730 37.970 12.653 7.141 人口中地位較低人群的百分比 程式碼：\nimport numpy as np import pandas as pd # 合併訓練和測試資料 combined_data = np.vstack((train_data, test_data)) print(\"Combined data shape:\", combined_data.shape) # 創建特徵名稱列表 (Boston Housing Dataset 的特徵) feature_names = [ 'CRIM', # 城鎮人均犯罪率 'ZN', # 佔地面積超過25000平方呎的住宅用地比例 'INDUS', # 每個城鎮非零售商業用地的比例 'CHAS', # Charles River 虛擬變數 (1 if tract bounds river; 0 otherwise) 'NOX', # 一氧化氮濃度 'RM', # 每棟住宅的平均房間數 'AGE', # 1940年之前建成的自用房屋比例 'DIS', # 到波士頓5個就業中心的加權距離 'RAD', # 到高速公路的可達性指數 'TAX', # 每10000美元的房產稅率 'PTRATIO', # 城鎮師生比例 'B', # 1000(Bk - 0.63)^2，其中Bk為城鎮中黑人的比例 'LSTAT' # 人口中地位較低人群的百分比 ] # 創建 DataFrame 以方便分析 df = pd.DataFrame(combined_data, columns=feature_names) # 分析每個特徵的範圍 feature_analysis = pd.DataFrame({ 'Min': df.min(), 'Max': df.max(), 'Mean': df.mean(), 'Std': df.std() }).round(3) print(\"\\n特徵值範圍分析:\") print(feature_analysis) ``` 準備資料 首先我們先做正規化處理(normalization)，常用的方法是減去特徵的平均值並除以標準差，使平均值為 0 且標準差為 1。 $$ x’ = \\frac{x-\\mu}{\\sigma} $$ mean = train_data.mean(axis=0) std = train_data.std(axis=0) train_data -= mean train_data /= std test_data -= mean test_data /= std 建立模型 一般來說，訓練資料愈少，overfitting 的情況會愈嚴重，所有我們採用較小型的神經網路。 from keras import models from keras import layers def build_model(): model = keras.Sequential([ layers.Dense(64, activation='relu'), layers.Dense(64, activation='relu'), layers.Dense(1) ]) model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) return model 注意到最後我們以 Dense(1) 結束，沒有套用激活函數，原因是我們希望輸出一個浮點數型別的數值，即迴歸值。若是套用 sigmoid 函數，則神經網路只能輸出 0 到 1 之間的預測值。在此例中，因為最後一層是純線性的，所以神經網路可以自由地預測任何範圍內的值。 我們這邊使用的評量指標是 mae，代表 \\(|\\text{y}_ \\text{pred}-\\text{y}_ \\text{true}|\\)，更能直觀的表達與目標值的差異，如 MAE = 0.5，代表與預測值的差異是 $500 美元。 K-fold 驗證 由於資料點很少，驗證資料也會很少，所以驗證分數會因驗證集的選用而有很大的變化，造成驗證分數會有很大的變異性(variance)，導致評斷模型優劣的可靠性降低。\n因此，我們可以採用K-fold 交叉驗證(K-fold cross validation)。一般會將資料拆分為 K 個區塊，通常 K = 4 or 5。\n示意圖：\n將 data 分成 K 個部分: data[0:n,:], data[n:2*n,:], data[2*n:3*n,:], data[3*n:4*n,:], data[4*n:5*n,:] 每次取其中一個區塊當驗證集，其餘區塊當訓練集，最後再取 K 次測試分數的平均值作為驗證分數。 $$ \\begin{array}{cccccccc} \u0026\\text{part 1}\u0026\\text{part 2}\u0026\\text{part 3}\u0026\\text{part 4}\u0026\\text{part 5}\\\\ \\hline \\text{1st fold} \u0026 \\boxed{\\red{\\text{驗證}}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\rightarrow \u0026 \\text{測試分數 \\#1}\\\\ \\text{2nd fold} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\red{\\text{驗證}}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\rightarrow \u0026 \\text{測試分數 \\#2}\\\\ \\text{3rd fold} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\red{\\text{驗證}}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\rightarrow \u0026 \\text{測試分數 \\#3}\\\\ \\text{4th fold} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\red{\\text{驗證}}} \u0026 \\boxed{\\text{訓練}} \u0026 \\rightarrow \u0026 \\text{測試分數 \\#4}\\\\ \\text{5th fold} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\text{訓練}} \u0026 \\boxed{\\red{\\text{驗證}}} \u0026 \\rightarrow \u0026 \\text{測試分數 \\#5} \\end{array} $$ from os import kill k = 5 n = len(train_data) // k epochs = 100 scores = [] for i in range(k): print('Processing fold #', i) val_data = train_data[i * n: (i+1) * n] val_targets = train_targets[i * n: (i+1) * n] partial_train_data = np.concatenate( [train_data[:i * n], train_data[(i+1) * n:]], axis=0 ) partial_train_targets = np.concatenate( [train_targets[:i * n], train_targets[(i+1) * n:]], axis=0 ) model = build_model() model.fit(partial_train_data, partial_train_targets, epochs=epochs, batch_size=16, verbose=0) val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0) scores.append(val_mae) 以此為例我們會得到 print(scores) print(np.mean(scores)) \u003e [1.720955491065979, 2.8763468265533447, 2.1907858848571777, 2.566359043121338, 2.54329252243042] \u003e 2.379547953605652 最後我們可以用求出來的最佳 epochs 代入全部資料，重新訓練最終的模型。 # 使用全部訓練數據重新訓練模型 final_model = build_model() final_history = final_model.fit( train_data, train_targets, epochs=best_epoch, # 使用找到的最佳 epoch 數 batch_size=16, verbose=1 ) 最後我們就可以用 model 來進行預測 predictions = model.predict(test_data) ","wordCount":"552","inLanguage":"zh-tw","datePublished":"2025-01-12T16:39:58+08:00","dateModified":"2025-01-12T16:39:58+08:00","author":{"@type":"Person","name":"Rain Hu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://intervalrain.github.io/ai/4_3/"},"publisher":{"@type":"Organization","name":"Rain Hu's Workspace","logo":{"@type":"ImageObject","url":"https://intervalrain.github.io/images/rain.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://intervalrain.github.io/ accesskey=h title="Rain Hu's Workspace (Alt + H)"><img src=https://intervalrain.github.io/images/rain.png alt aria-label=logo height=35>Rain Hu's Workspace</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://intervalrain.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://intervalrain.github.io/aboutme title="About me"><span>About me</span></a></li><li><a href=https://intervalrain.github.io/archives title=Archives><span>Archives</span></a></li><li><a href=https://intervalrain.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://intervalrain.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://intervalrain.github.io/csharp/csharp title=C#><span>C#</span></a></li><li><a href=https://intervalrain.github.io/csindex title=CS><span>CS</span></a></li><li><a href=https://intervalrain.github.io/leetcode title=LeetCode><span>LeetCode</span></a></li><li><a href=https://intervalrain.github.io/ai title=AI><span>AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://intervalrain.github.io/>首頁</a></div><h1 class="post-title entry-hint-parent">[AI] 迴歸問題</h1><div class=post-description>Regression problem</div><div class=post-meta><span title='2025-01-12 16:39:58 +0800 +0800'>January 12, 2025</span>&nbsp;·&nbsp;3 分鐘&nbsp;·&nbsp;Rain Hu&nbsp;|&nbsp;<a href=https://github.com/intervalrain/intervalrain.github.io/tree/main/content//AI/4_3.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目錄</span></summary><div class=inner><ul><li><a href=#%e8%aa%8d%e8%ad%98%e6%b3%a2%e5%a3%ab%e9%a0%93%e4%bd%8f%e6%88%bf%e5%83%b9%e8%b3%87%e6%96%99%e9%9b%86 aria-label=認識波士頓住房價資料集>認識波士頓住房價資料集</a></li><li><a href=#%e6%ba%96%e5%82%99%e8%b3%87%e6%96%99 aria-label=準備資料>準備資料</a></li><li><a href=#%e5%bb%ba%e7%ab%8b%e6%a8%a1%e5%9e%8b aria-label=建立模型>建立模型</a></li><li><a href=#k-fold-%e9%a9%97%e8%ad%89 aria-label="K-fold 驗證">K-fold 驗證</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=認識波士頓住房價資料集>認識波士頓住房價資料集<a hidden class=anchor aria-hidden=true href=#認識波士頓住房價資料集>#</a></h2><ul><li>透過 tensorflow 引入資料集<ul><li>波士頓住房價資料集是 1970 年代中期波士頓的郊區資料，包含犯罪率、當地財產稅等。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> boston_housing
</span></span><span style=display:flex><span>(train_data, train_targets), (test_data, test_targets) <span style=color:#f92672>=</span> boston_housing<span style=color:#f92672>.</span>load_data()
</span></span></code></pre></div><ul><li>與先前兩個範例最大的差別是，資料點明顯較少，共 404 + 102 = 506 筆。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(train_data<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>print(train_targets<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>print(test_data<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>print(test_targets<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;</span> (<span style=color:#ae81ff>404</span>, <span style=color:#ae81ff>13</span>)
</span></span><span style=display:flex><span>  (<span style=color:#ae81ff>404</span>,)
</span></span><span style=display:flex><span>  (<span style=color:#ae81ff>102</span>, <span style=color:#ae81ff>13</span>)
</span></span><span style=display:flex><span>  (<span style=color:#ae81ff>102</span>,)
</span></span></code></pre></div><ul><li>需注意，每個特徵都有不同的單位刻度<details><summary>查看特徵分布</summary><ul><li><p>特徵值範圍分析:</p><table><thead><tr><th>特徵</th><th>最小值</th><th>最大值</th><th>平均值</th><th>標準差</th><th>特徵意義</th></tr></thead><tbody><tr><td>CRIM</td><td>0.006</td><td>88.976</td><td>3.614</td><td>8.602</td><td>城鎮人均犯罪率</td></tr><tr><td>ZN</td><td>0.000</td><td>100.000</td><td>11.364</td><td>23.322</td><td>佔地面積超過25000平方呎的住宅用地比例</td></tr><tr><td>INDUS</td><td>0.460</td><td>27.740</td><td>11.137</td><td>6.860</td><td>每個城鎮非零售商業用地的比例</td></tr><tr><td>CHAS</td><td>0.000</td><td>1.000</td><td>0.069</td><td>0.254</td><td>Charles River 虛擬變數 (1 if tract bounds river; 0 otherwise)</td></tr><tr><td>NOX</td><td>0.385</td><td>0.871</td><td>0.555</td><td>0.116</td><td>一氧化氮濃度</td></tr><tr><td>RM</td><td>3.561</td><td>8.780</td><td>6.285</td><td>0.703</td><td>每棟住宅的平均房間數</td></tr><tr><td>AGE</td><td>2.900</td><td>100.000</td><td>68.575</td><td>28.149</td><td>1940年之前建成的自用房屋比例</td></tr><tr><td>DIS</td><td>1.130</td><td>12.126</td><td>3.795</td><td>2.106</td><td>到波士頓5個就業中心的加權距離</td></tr><tr><td>RAD</td><td>1.000</td><td>24.000</td><td>9.549</td><td>8.707</td><td>到高速公路的可達性指數</td></tr><tr><td>TAX</td><td>187.000</td><td>711.000</td><td>408.237</td><td>168.537</td><td>每10000美元的房產稅率</td></tr><tr><td>PTRATIO</td><td>12.600</td><td>22.000</td><td>18.456</td><td>2.165</td><td>城鎮師生比例</td></tr><tr><td>B</td><td>0.320</td><td>396.900</td><td>356.674</td><td>91.295</td><td>1000(Bk - 0.63)^2，其中Bk為城鎮中黑人的比例</td></tr><tr><td>LSTAT</td><td>1.730</td><td>37.970</td><td>12.653</td><td>7.141</td><td>人口中地位較低人群的百分比</td></tr></tbody></table></li><li><p>程式碼：</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>    <span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 合併訓練和測試資料</span>
</span></span><span style=display:flex><span>    combined_data <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>vstack((train_data, test_data))
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Combined data shape:&#34;</span>, combined_data<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 創建特徵名稱列表 (Boston Housing Dataset 的特徵)</span>
</span></span><span style=display:flex><span>    feature_names <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;CRIM&#39;</span>,     <span style=color:#75715e># 城鎮人均犯罪率</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;ZN&#39;</span>,       <span style=color:#75715e># 佔地面積超過25000平方呎的住宅用地比例</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;INDUS&#39;</span>,    <span style=color:#75715e># 每個城鎮非零售商業用地的比例</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;CHAS&#39;</span>,     <span style=color:#75715e># Charles River 虛擬變數 (1 if tract bounds river; 0 otherwise)</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;NOX&#39;</span>,      <span style=color:#75715e># 一氧化氮濃度</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;RM&#39;</span>,       <span style=color:#75715e># 每棟住宅的平均房間數</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;AGE&#39;</span>,      <span style=color:#75715e># 1940年之前建成的自用房屋比例</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;DIS&#39;</span>,      <span style=color:#75715e># 到波士頓5個就業中心的加權距離</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;RAD&#39;</span>,      <span style=color:#75715e># 到高速公路的可達性指數</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;TAX&#39;</span>,      <span style=color:#75715e># 每10000美元的房產稅率</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;PTRATIO&#39;</span>,  <span style=color:#75715e># 城鎮師生比例</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;B&#39;</span>,        <span style=color:#75715e># 1000(Bk - 0.63)^2，其中Bk為城鎮中黑人的比例</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;LSTAT&#39;</span>     <span style=color:#75715e># 人口中地位較低人群的百分比</span>
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 創建 DataFrame 以方便分析</span>
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(combined_data, columns<span style=color:#f92672>=</span>feature_names)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 分析每個特徵的範圍</span>
</span></span><span style=display:flex><span>    feature_analysis <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame({
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;Min&#39;</span>: df<span style=color:#f92672>.</span>min(),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;Max&#39;</span>: df<span style=color:#f92672>.</span>max(),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;Mean&#39;</span>: df<span style=color:#f92672>.</span>mean(),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;Std&#39;</span>: df<span style=color:#f92672>.</span>std()
</span></span><span style=display:flex><span>    })<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>特徵值範圍分析:&#34;</span>)
</span></span><span style=display:flex><span>    print(feature_analysis)
</span></span><span style=display:flex><span>    <span style=color:#960050;background-color:#1e0010>```</span>
</span></span></code></pre></div></li></ul></details></li></ul><h2 id=準備資料>準備資料<a hidden class=anchor aria-hidden=true href=#準備資料>#</a></h2><ul><li>首先我們先做正規化處理(normalization)，常用的方法是減去特徵的<strong>平均值</strong>並除以<strong>標準差</strong>，使平均值為 0 且標準差為 1。
$$
x&rsquo; = \frac{x-\mu}{\sigma}
$$</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>mean <span style=color:#f92672>=</span> train_data<span style=color:#f92672>.</span>mean(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>std <span style=color:#f92672>=</span> train_data<span style=color:#f92672>.</span>std(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>train_data <span style=color:#f92672>-=</span> mean
</span></span><span style=display:flex><span>train_data <span style=color:#f92672>/=</span> std
</span></span><span style=display:flex><span>test_data <span style=color:#f92672>-=</span> mean
</span></span><span style=display:flex><span>test_data <span style=color:#f92672>/=</span> std
</span></span></code></pre></div><h2 id=建立模型>建立模型<a hidden class=anchor aria-hidden=true href=#建立模型>#</a></h2><ul><li>一般來說，訓練資料愈少，overfitting 的情況會愈嚴重，所有我們採用較小型的神經網路。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>build_model</span>():
</span></span><span style=display:flex><span>    model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rmsprop&#39;</span>, loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mse&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;mae&#39;</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> model
</span></span></code></pre></div><ul><li>注意到最後我們以 <code>Dense(1)</code> 結束，沒有套用激活函數，原因是我們希望輸出一個浮點數型別的數值，即迴歸值。若是套用 sigmoid 函數，則神經網路只能輸出 0 到 1 之間的預測值。在此例中，因為最後一層是純線性的，所以神經網路可以自由地預測任何範圍內的值。</li><li>我們這邊使用的評量指標是 <code>mae</code>，代表 \(|\text{y}_ \text{pred}-\text{y}_ \text{true}|\)，更能直觀的表達與目標值的差異，如 MAE = 0.5，代表與預測值的差異是 $500 美元。</li></ul><h2 id=k-fold-驗證>K-fold 驗證<a hidden class=anchor aria-hidden=true href=#k-fold-驗證>#</a></h2><ul><li><p>由於資料點很少，驗證資料也會很少，所以驗證分數會因驗證集的選用而有很大的變化，造成驗證分數會有很大的變異性(variance)，導致評斷模型優劣的可靠性降低。</p></li><li><p>因此，我們可以採用<strong>K-fold 交叉驗證(K-fold cross validation)</strong>。一般會將資料拆分為 K 個區塊，通常 K = 4 or 5。</p></li><li><p>示意圖：</p><ul><li>將 data 分成 K 個部分: <code>data[0:n,:]</code>, <code>data[n:2*n,:]</code>, <code>data[2*n:3*n,:]</code>, <code>data[3*n:4*n,:]</code>, <code>data[4*n:5*n,:]</code></li><li>每次取其中一個區塊當驗證集，其餘區塊當訓練集，最後再取 K 次測試分數的平均值作為驗證分數。
$$
\begin{array}{cccccccc}
&\text{part 1}&\text{part 2}&\text{part 3}&\text{part 4}&\text{part 5}\\
\hline
\text{1st fold} & \boxed{\red{\text{驗證}}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \rightarrow & \text{測試分數 \#1}\\
\text{2nd fold} & \boxed{\text{訓練}} & \boxed{\red{\text{驗證}}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \rightarrow & \text{測試分數 \#2}\\
\text{3rd fold} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\red{\text{驗證}}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \rightarrow & \text{測試分數 \#3}\\
\text{4th fold} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\red{\text{驗證}}} & \boxed{\text{訓練}} & \rightarrow & \text{測試分數 \#4}\\
\text{5th fold} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\text{訓練}} & \boxed{\red{\text{驗證}}} & \rightarrow & \text{測試分數 \#5}
\end{array}
$$</li></ul></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> os <span style=color:#f92672>import</span> kill
</span></span><span style=display:flex><span>k <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>n <span style=color:#f92672>=</span> len(train_data) <span style=color:#f92672>//</span> k
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>scores <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(k):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;Processing fold #&#39;</span>, i)
</span></span><span style=display:flex><span>    val_data <span style=color:#f92672>=</span> train_data[i <span style=color:#f92672>*</span> n: (i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>*</span> n]
</span></span><span style=display:flex><span>    val_targets <span style=color:#f92672>=</span> train_targets[i <span style=color:#f92672>*</span> n: (i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>*</span> n]
</span></span><span style=display:flex><span>    partial_train_data <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>concatenate(
</span></span><span style=display:flex><span>        [train_data[:i <span style=color:#f92672>*</span> n],
</span></span><span style=display:flex><span>         train_data[(i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>*</span> n:]],
</span></span><span style=display:flex><span>        axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    partial_train_targets <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>concatenate(
</span></span><span style=display:flex><span>        [train_targets[:i <span style=color:#f92672>*</span> n],
</span></span><span style=display:flex><span>         train_targets[(i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>*</span> n:]],
</span></span><span style=display:flex><span>        axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    model <span style=color:#f92672>=</span> build_model()
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>fit(partial_train_data, partial_train_targets, 
</span></span><span style=display:flex><span>              epochs<span style=color:#f92672>=</span>epochs, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    val_mse, val_mae <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>evaluate(val_data, val_targets, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    scores<span style=color:#f92672>.</span>append(val_mae)
</span></span></code></pre></div><ul><li>以此為例我們會得到</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(scores)
</span></span><span style=display:flex><span>print(np<span style=color:#f92672>.</span>mean(scores))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;</span> [<span style=color:#ae81ff>1.720955491065979</span>, <span style=color:#ae81ff>2.8763468265533447</span>, <span style=color:#ae81ff>2.1907858848571777</span>, <span style=color:#ae81ff>2.566359043121338</span>, <span style=color:#ae81ff>2.54329252243042</span>]
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>2.379547953605652</span>
</span></span></code></pre></div><ul><li>最後我們可以用求出來的最佳 epochs 代入全部資料，重新訓練最終的模型。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 使用全部訓練數據重新訓練模型</span>
</span></span><span style=display:flex><span>final_model <span style=color:#f92672>=</span> build_model()
</span></span><span style=display:flex><span>final_history <span style=color:#f92672>=</span> final_model<span style=color:#f92672>.</span>fit(
</span></span><span style=display:flex><span>    train_data, train_targets,
</span></span><span style=display:flex><span>    epochs<span style=color:#f92672>=</span>best_epoch,  <span style=color:#75715e># 使用找到的最佳 epoch 數</span>
</span></span><span style=display:flex><span>    batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>,
</span></span><span style=display:flex><span>    verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><ul><li>最後我們就可以用 model 來進行預測</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>predictions <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(test_data)
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://intervalrain.github.io/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=https://intervalrain.github.io/ai/4_2/><span class=title>« 上一頁</span><br><span>[AI] 多元分類問題</span>
</a><a class=next href=https://intervalrain.github.io/ai/5_1/><span class=title>下一頁 »</span><br><span>[AI] 普適化</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://intervalrain.github.io/>Rain Hu's Workspace</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="複製";function s(){t.innerHTML="已複製！",setTimeout(()=>{t.innerHTML="複製"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>