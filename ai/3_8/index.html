<!doctype html><html lang=zh-tw dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[AI] 3-8. 客製化 Training | Rain Hu's Workspace</title><meta name=keywords content="AI"><meta name=description content="How to customize training in Keras"><meta name=author content="Rain Hu"><link rel=canonical href=https://intervalrain.github.io/><meta name=google-site-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0cefe5a1d95e3d0f0cce057d37c60cd238d1a4af825090f831a18f21671f621d.css integrity="sha256-DO/lodlePQ8MzgV9N8YM0jjRpK+CUJD4MaGPIWcfYh0=" rel="preload stylesheet" as=style><link rel=icon href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=16x16 href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=32x32 href=https://intervalrain.github.io/images/rain.png><link rel=apple-touch-icon href=https://intervalrain.github.io/images/rain.png><link rel=mask-icon href=https://intervalrain.github.io/images/rain.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-tw href=https://intervalrain.github.io/ai/3_8/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script><script async src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script src=https://utteranc.es/client.js repo=intervalrain.github.io issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script><meta property="og:url" content="https://intervalrain.github.io/ai/3_8/"><meta property="og:site_name" content="Rain Hu's Workspace"><meta property="og:title" content="[AI] 3-8. 客製化 Training"><meta property="og:description" content="How to customize training in Keras"><meta property="og:locale" content="zh-tw"><meta property="og:type" content="article"><meta property="article:section" content="ai"><meta property="article:published_time" content="2024-12-27T15:49:27+08:00"><meta property="article:modified_time" content="2024-12-27T15:49:27+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="[AI] 3-8. 客製化 Training"><meta name=twitter:description content="How to customize training in Keras"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"[AI] 3-8. 客製化 Training","item":"https://intervalrain.github.io/ai/3_8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[AI] 3-8. 客製化 Training","name":"[AI] 3-8. 客製化 Training","description":"How to customize training in Keras","keywords":["AI"],"articleBody":" 內建的 fit() 只適用於監督式學習(supervised learning)，然而不是所有的機器學習任務都適用，如生成式學習(generative learning)、自監督式學習(self-supervised learning)、強化式學習(reinforcement learning) 等。 監督式學習的訓練 在實作 Keras 訓練迴圈時有兩個重要細節： training 參數: 某些層(如 Dropout)在訓練和推論時行為不同 訓練時需設定 training=True 推論時設定 training=False\n模型權重分類:\nTrainable weights: 可訓練的權重 Non-trainable weights: 不可訓練的權重(如 BatchNormalization 層的統計值) 取梯度時應使用 model.trainable_weights 以下是完整可執行範例:\nimport tensorflow as tf from tensorflow import keras import numpy as np # 建立範例資料 x_train = np.random.random((1000, 28, 28)) y_train = np.random.randint(10, size=(1000,)) # 建立包含 Dropout 和 BatchNormalization 的模型 model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)), keras.layers.Dense(128), keras.layers.BatchNormalization(), keras.layers.Dropout(0.5), keras.layers.Dense(10) ]) # 損失函數與優化器 loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True) optimizer = keras.optimizers.Adam(learning_rate=1e-3) # 自定義訓練步驟 @tf.function def train_step(inputs, targets): with tf.GradientTape() as tape: # 訓練模式前向傳播 predictions = model(inputs, training=True) loss = loss_fn(targets, predictions) # 計算可訓練權重的梯度 gradients = tape.gradient(loss, model.trainable_weights) optimizer.apply_gradients(zip(gradients, model.trainable_weights)) return loss # 訓練迴圈 batch_size = 32 for epoch in range(5): print(f\"\\nEpoch {epoch+1}\") for step in range(0, len(x_train), batch_size): x_batch = x_train[step:step + batch_size] y_batch = y_train[step:step + batch_size] loss = train_step(x_batch, y_batch) if step % 200 == 0: print(f\"Step {step}: loss = {loss:.4f}\") # 推論時使用 training=False test_predictions = model(x_train[:1], training=False) 評量指標 在訓練期間，我們可以用 Keras 的評量指標來查詢當前的指標值，我們會用到幾個函式: update_state(y_true, y_pred) result() reset_state() import tensorflow as tf from tensorflow import keras import numpy as np # 建立模型 model = keras.Sequential([ keras.layers.Dense(64, activation='relu'), keras.layers.Dense(10, activation='softmax') ]) # 初始化指標追蹤器 accuracy_tracker = keras.metrics.SparseCategoricalAccuracy() loss_tracker = keras.metrics.Mean() # 訓練步驟 @tf.function def train_step(inputs, targets): with tf.GradientTape() as tape: predictions = model(inputs, training=True) loss = tf.keras.losses.sparse_categorical_crossentropy(targets, predictions) # 更新梯度 gradients = tape.gradient(loss, model.trainable_weights) optimizer.apply_gradients(zip(gradients, model.trainable_weights)) # 更新指標 accuracy_tracker.update_state(targets, predictions) loss_tracker.update_state(loss) return loss # 訓練迴圈 x_train = np.random.random((1000, 32)) y_train = np.random.randint(10, size=(1000,)) optimizer = keras.optimizers.Adam() batch_size = 32 for epoch in range(3): # 重置每個 epoch 的指標 accuracy_tracker.reset_state() loss_tracker.reset_state() for step in range(0, len(x_train), batch_size): x_batch = x_train[step:step + batch_size] y_batch = y_train[step:step + batch_size] loss = train_step(x_batch, y_batch) if step % 200 == 0: print( f\"Step {step}: \", f\"Loss: {loss_tracker.result():.4f}, \", f\"Accuracy: {accuracy_tracker.result():.4f}\" ) 完整的訓練與評估迴圈 設計練訓函式 model = get_mnist_model() loss_fn = keras.losses.SparseCategoricalCrossentropy() optimizer = keras.optimizers.RMSprop() metrics = [keras.metrics.SparseCategoricalAccuracy()] loss_tracking_metric = keras.metrics.Mean() def train_step(inputs, targets): with tf.GradientTape() as tape: predictions = model(inputs, training=True) loss = loss_fn(targets, predictions) gradients = tape.gradient(loss, model.trainable_weights) optimizer.apply_gradients(zip(gradients, model.trainable_weights)) logs = {} for metric in metrics: metric.update_state(targets, predictions) logs[metric.name] = metric.result() loss_tracking_metric.update_state(loss) logs[\"loss\"] = loss_tracking_metric.result() return logs 重置評量指標 def reset_metrics(): for metric in metrics: metric.reset_state() loss_tracking_metric.reset_state() 設計訓練迴圈 training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)) training_dataset = training_dataset.batch(32) epochs = 3 for epoch in range(epochs): reset_metrics() for inputs_batch, targets_batch in training_dataset: logs = train_step(inputs_batch, targets_batch) print(f\"Results at the end of epoch {epoch}\") for key, value in logs.items(): print(f\"...{key}: {value:.4f}\") 設計評估迴圈 def test_step(inputs, targets): predictions = model(inputs, training=False) loss = loss_fn(targets, predictions) logs = {} for metric in metrics: metric.update_state(targets, predictions) logs[\"val_\" + metric.name] = metric.result() loss_tracking_metric.update_state(loss) logs[\"val_loss\"] = loss_tracking_metric.result() return logs val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)) val_dataset = val_dataset.batch(32) reset_metrics() for inputs_batch, targets_batch in val_dataset: logs = test_step(inputs_batch, targets_batch) print(\"Evaluation results:\") for key, value in logs.items(): print(f\"...{key}: {value:.4f}\") 利用 tf.function 來加速 只要在要編譯的函式前加上 @tf.function 裝飾器就可以將 TensorFlow 程式碼編譯成運算圖(computation graph)。 搭配 fit() 和自定義的訓練的迴圈 from tensorflow import keras from tensorflow.keras import layers import tensorflow as tf # 1. 將 optimizer 移到類別內部 class CustomModel(keras.Model): def __init__(self, inputs, outputs): super().__init__(inputs=inputs, outputs=outputs) self.loss_tracker = keras.metrics.Mean(name=\"loss\") # 2. 移到類別內 self.optimizer = keras.optimizers.RMSprop() # 3. 加入 optimizer self.loss_fn = keras.losses.SparseCategoricalCrossentropy() def train_step(self, data): inputs, targets = data with tf.GradientTape() as tape: predictions = self(inputs, training=True) loss = self.loss_fn(targets, predictions) gradients = tape.gradient(loss, self.trainable_weights) self.optimizer.apply_gradients(zip(gradients, self.trainable_weights)) # 4. 使用 self.optimizer self.loss_tracker.update_state(loss) # 5. 使用 self.loss_tracker return {\"loss\": self.loss_tracker.result()} @property def metrics(self): return [self.loss_tracker] # 6. 使用 self.loss_trackerxqf # 建立模型 inputs = keras.Input(shape=(28 * 28,)) features = layers.Dense(512, activation=\"relu\")(inputs) features = layers.Dropout(0.5)(features) outputs = layers.Dense(10, activation=\"softmax\")(features) model = CustomModel(inputs=inputs, outputs=outputs) model.compile() # 7. 移除 optimizer 參數 model.fit(train_images, train_labels, epochs=3) ","wordCount":"583","inLanguage":"zh-tw","datePublished":"2024-12-27T15:49:27+08:00","dateModified":"2024-12-27T15:49:27+08:00","author":{"@type":"Person","name":"Rain Hu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://intervalrain.github.io/ai/3_8/"},"publisher":{"@type":"Organization","name":"Rain Hu's Workspace","logo":{"@type":"ImageObject","url":"https://intervalrain.github.io/images/rain.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://intervalrain.github.io/ accesskey=h title="Rain Hu's Workspace (Alt + H)"><img src=https://intervalrain.github.io/images/rain.png alt aria-label=logo height=35>Rain Hu's Workspace</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://intervalrain.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://intervalrain.github.io/aboutme title="About me"><span>About me</span></a></li><li><a href=https://intervalrain.github.io/archives title=Archives><span>Archives</span></a></li><li><a href=https://intervalrain.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://intervalrain.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://intervalrain.github.io/csharp/csharp title=C#><span>C#</span></a></li><li><a href=https://intervalrain.github.io/csindex title=CS><span>CS</span></a></li><li><a href=https://intervalrain.github.io/leetcode title=LeetCode><span>LeetCode</span></a></li><li><a href=https://intervalrain.github.io/ai title=AI><span>AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://intervalrain.github.io/>首頁</a></div><h1 class="post-title entry-hint-parent">[AI] 3-8. 客製化 Training</h1><div class=post-description>How to customize training in Keras</div><div class=post-meta><span title='2024-12-27 15:49:27 +0800 +0800'>December 27, 2024</span>&nbsp;·&nbsp;3 分鐘&nbsp;·&nbsp;Rain Hu&nbsp;|&nbsp;<a href=https://github.com/intervalrain/intervalrain.github.io/tree/main/content//AI/3_8.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目錄</span></summary><div class=inner><ul><li><a href=#%e7%9b%a3%e7%9d%a3%e5%bc%8f%e5%ad%b8%e7%bf%92%e7%9a%84%e8%a8%93%e7%b7%b4 aria-label=監督式學習的訓練>監督式學習的訓練</a></li><li><a href=#%e8%a9%95%e9%87%8f%e6%8c%87%e6%a8%99 aria-label=評量指標>評量指標</a></li><li><a href=#%e5%ae%8c%e6%95%b4%e7%9a%84%e8%a8%93%e7%b7%b4%e8%88%87%e8%a9%95%e4%bc%b0%e8%bf%b4%e5%9c%88 aria-label=完整的訓練與評估迴圈>完整的訓練與評估迴圈</a><ul><li><a href=#%e8%a8%ad%e8%a8%88%e7%b7%b4%e8%a8%93%e5%87%bd%e5%bc%8f aria-label=設計練訓函式>設計練訓函式</a></li><li><a href=#%e9%87%8d%e7%bd%ae%e8%a9%95%e9%87%8f%e6%8c%87%e6%a8%99 aria-label=重置評量指標>重置評量指標</a></li><li><a href=#%e8%a8%ad%e8%a8%88%e8%a8%93%e7%b7%b4%e8%bf%b4%e5%9c%88 aria-label=設計訓練迴圈>設計訓練迴圈</a></li><li><a href=#%e8%a8%ad%e8%a8%88%e8%a9%95%e4%bc%b0%e8%bf%b4%e5%9c%88 aria-label=設計評估迴圈>設計評估迴圈</a></li></ul></li><li><a href=#%e5%88%a9%e7%94%a8-tffunction-%e4%be%86%e5%8a%a0%e9%80%9f aria-label="利用 tf.function 來加速">利用 tf.function 來加速</a></li><li><a href=#%e6%90%ad%e9%85%8d-fit-%e5%92%8c%e8%87%aa%e5%ae%9a%e7%be%a9%e7%9a%84%e8%a8%93%e7%b7%b4%e7%9a%84%e8%bf%b4%e5%9c%88 aria-label="搭配 fit() 和自定義的訓練的迴圈">搭配 fit() 和自定義的訓練的迴圈</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><ul><li>內建的 <code>fit()</code> 只適用於<strong>監督式學習(supervised learning)</strong>，然而不是所有的機器學習任務都適用，如<strong>生成式學習(generative learning)</strong>、<strong>自監督式學習(self-supervised learning)</strong>、<strong>強化式學習(reinforcement learning)</strong> 等。</li></ul><h2 id=監督式學習的訓練>監督式學習的訓練<a hidden class=anchor aria-hidden=true href=#監督式學習的訓練>#</a></h2><ul><li>在實作 Keras 訓練迴圈時有兩個重要細節：<ol><li><p>training 參數:
某些層(如 Dropout)在訓練和推論時行為不同
訓練時需設定 <code>training=True</code>
推論時設定 <code>training=False</code></p></li><li><p>模型權重分類:</p><ul><li>Trainable weights: 可訓練的權重</li><li>Non-trainable weights: 不可訓練的權重(如 BatchNormalization 層的統計值)
取梯度時應使用 <code>model.trainable_weights</code></li></ul></li></ol></li></ul><p>以下是完整可執行範例:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立範例資料</span>
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random((<span style=color:#ae81ff>1000</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>y_train <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>10</span>, size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1000</span>,))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立包含 Dropout 和 BatchNormalization 的模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Flatten(input_shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>)),
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>128</span>),
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>BatchNormalization(),
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 損失函數與優化器</span>
</span></span><span style=display:flex><span>loss_fn <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>losses<span style=color:#f92672>.</span>SparseCategoricalCrossentropy(from_logits<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>Adam(learning_rate<span style=color:#f92672>=</span><span style=color:#ae81ff>1e-3</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 自定義訓練步驟</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@tf.function</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_step</span>(inputs, targets):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>GradientTape() <span style=color:#66d9ef>as</span> tape:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練模式前向傳播</span>
</span></span><span style=display:flex><span>        predictions <span style=color:#f92672>=</span> model(inputs, training<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> loss_fn(targets, predictions)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 計算可訓練權重的梯度</span>
</span></span><span style=display:flex><span>    gradients <span style=color:#f92672>=</span> tape<span style=color:#f92672>.</span>gradient(loss, model<span style=color:#f92672>.</span>trainable_weights)
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>.</span>apply_gradients(zip(gradients, model<span style=color:#f92672>.</span>trainable_weights))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> loss
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 訓練迴圈</span>
</span></span><span style=display:flex><span>batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> step <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, len(x_train), batch_size):
</span></span><span style=display:flex><span>        x_batch <span style=color:#f92672>=</span> x_train[step:step <span style=color:#f92672>+</span> batch_size]
</span></span><span style=display:flex><span>        y_batch <span style=color:#f92672>=</span> y_train[step:step <span style=color:#f92672>+</span> batch_size]
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> train_step(x_batch, y_batch)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> step <span style=color:#f92672>%</span> <span style=color:#ae81ff>200</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Step </span><span style=color:#e6db74>{</span>step<span style=color:#e6db74>}</span><span style=color:#e6db74>: loss = </span><span style=color:#e6db74>{</span>loss<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 推論時使用 training=False</span>
</span></span><span style=display:flex><span>test_predictions <span style=color:#f92672>=</span> model(x_train[:<span style=color:#ae81ff>1</span>], training<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span></code></pre></div><h2 id=評量指標>評量指標<a hidden class=anchor aria-hidden=true href=#評量指標>#</a></h2><ul><li>在訓練期間，我們可以用 Keras 的評量指標來查詢當前的指標值，我們會用到幾個函式:<ul><li><code>update_state(y_true, y_pred)</code></li><li><code>result()</code></li><li><code>reset_state()</code></li></ul></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;softmax&#39;</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 初始化指標追蹤器</span>
</span></span><span style=display:flex><span>accuracy_tracker <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>SparseCategoricalAccuracy()
</span></span><span style=display:flex><span>loss_tracker <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>Mean()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 訓練步驟</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@tf.function</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_step</span>(inputs, targets):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>GradientTape() <span style=color:#66d9ef>as</span> tape:
</span></span><span style=display:flex><span>        predictions <span style=color:#f92672>=</span> model(inputs, training<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>losses<span style=color:#f92672>.</span>sparse_categorical_crossentropy(targets, predictions)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更新梯度</span>
</span></span><span style=display:flex><span>    gradients <span style=color:#f92672>=</span> tape<span style=color:#f92672>.</span>gradient(loss, model<span style=color:#f92672>.</span>trainable_weights)
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>.</span>apply_gradients(zip(gradients, model<span style=color:#f92672>.</span>trainable_weights))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更新指標</span>
</span></span><span style=display:flex><span>    accuracy_tracker<span style=color:#f92672>.</span>update_state(targets, predictions)
</span></span><span style=display:flex><span>    loss_tracker<span style=color:#f92672>.</span>update_state(loss)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> loss
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 訓練迴圈</span>
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random((<span style=color:#ae81ff>1000</span>, <span style=color:#ae81ff>32</span>))
</span></span><span style=display:flex><span>y_train <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>10</span>, size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1000</span>,))
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>Adam()
</span></span><span style=display:flex><span>batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>3</span>):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 重置每個 epoch 的指標</span>
</span></span><span style=display:flex><span>    accuracy_tracker<span style=color:#f92672>.</span>reset_state()
</span></span><span style=display:flex><span>    loss_tracker<span style=color:#f92672>.</span>reset_state()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> step <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, len(x_train), batch_size):
</span></span><span style=display:flex><span>        x_batch <span style=color:#f92672>=</span> x_train[step:step <span style=color:#f92672>+</span> batch_size]
</span></span><span style=display:flex><span>        y_batch <span style=color:#f92672>=</span> y_train[step:step <span style=color:#f92672>+</span> batch_size]
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> train_step(x_batch, y_batch)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> step <span style=color:#f92672>%</span> <span style=color:#ae81ff>200</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            print(
</span></span><span style=display:flex><span>                <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Step </span><span style=color:#e6db74>{</span>step<span style=color:#e6db74>}</span><span style=color:#e6db74>: &#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Loss: </span><span style=color:#e6db74>{</span>loss_tracker<span style=color:#f92672>.</span>result()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, &#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{</span>accuracy_tracker<span style=color:#f92672>.</span>result()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>            )
</span></span></code></pre></div><h2 id=完整的訓練與評估迴圈>完整的訓練與評估迴圈<a hidden class=anchor aria-hidden=true href=#完整的訓練與評估迴圈>#</a></h2><h3 id=設計練訓函式>設計練訓函式<a hidden class=anchor aria-hidden=true href=#設計練訓函式>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model <span style=color:#f92672>=</span> get_mnist_model()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>loss_fn <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>losses<span style=color:#f92672>.</span>SparseCategoricalCrossentropy()
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>RMSprop()
</span></span><span style=display:flex><span>metrics <span style=color:#f92672>=</span> [keras<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>SparseCategoricalAccuracy()]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>loss_tracking_metric <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>Mean()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_step</span>(inputs, targets):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>GradientTape() <span style=color:#66d9ef>as</span> tape:
</span></span><span style=display:flex><span>        predictions <span style=color:#f92672>=</span> model(inputs, training<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> loss_fn(targets, predictions)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    gradients <span style=color:#f92672>=</span> tape<span style=color:#f92672>.</span>gradient(loss, model<span style=color:#f92672>.</span>trainable_weights)
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>.</span>apply_gradients(zip(gradients, model<span style=color:#f92672>.</span>trainable_weights))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    logs <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> metric <span style=color:#f92672>in</span> metrics:
</span></span><span style=display:flex><span>        metric<span style=color:#f92672>.</span>update_state(targets, predictions)
</span></span><span style=display:flex><span>        logs[metric<span style=color:#f92672>.</span>name] <span style=color:#f92672>=</span> metric<span style=color:#f92672>.</span>result()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    loss_tracking_metric<span style=color:#f92672>.</span>update_state(loss)
</span></span><span style=display:flex><span>    logs[<span style=color:#e6db74>&#34;loss&#34;</span>] <span style=color:#f92672>=</span> loss_tracking_metric<span style=color:#f92672>.</span>result()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> logs
</span></span></code></pre></div><h3 id=重置評量指標>重置評量指標<a hidden class=anchor aria-hidden=true href=#重置評量指標>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>reset_metrics</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> metric <span style=color:#f92672>in</span> metrics:
</span></span><span style=display:flex><span>        metric<span style=color:#f92672>.</span>reset_state()
</span></span><span style=display:flex><span>    loss_tracking_metric<span style=color:#f92672>.</span>reset_state()
</span></span></code></pre></div><h3 id=設計訓練迴圈>設計訓練迴圈<a hidden class=anchor aria-hidden=true href=#設計訓練迴圈>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>training_dataset <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>Dataset<span style=color:#f92672>.</span>from_tensor_slices((train_images, train_labels))
</span></span><span style=display:flex><span>training_dataset <span style=color:#f92672>=</span> training_dataset<span style=color:#f92672>.</span>batch(<span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(epochs):
</span></span><span style=display:flex><span>    reset_metrics()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs_batch, targets_batch <span style=color:#f92672>in</span> training_dataset:
</span></span><span style=display:flex><span>        logs <span style=color:#f92672>=</span> train_step(inputs_batch, targets_batch)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Results at the end of epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> key, value <span style=color:#f92672>in</span> logs<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;...</span><span style=color:#e6db74>{</span>key<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>value<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h3 id=設計評估迴圈>設計評估迴圈<a hidden class=anchor aria-hidden=true href=#設計評估迴圈>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_step</span>(inputs, targets):
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> model(inputs, training<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    loss <span style=color:#f92672>=</span> loss_fn(targets, predictions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    logs <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> metric <span style=color:#f92672>in</span> metrics:
</span></span><span style=display:flex><span>        metric<span style=color:#f92672>.</span>update_state(targets, predictions)
</span></span><span style=display:flex><span>        logs[<span style=color:#e6db74>&#34;val_&#34;</span> <span style=color:#f92672>+</span> metric<span style=color:#f92672>.</span>name] <span style=color:#f92672>=</span> metric<span style=color:#f92672>.</span>result()
</span></span><span style=display:flex><span>    loss_tracking_metric<span style=color:#f92672>.</span>update_state(loss)
</span></span><span style=display:flex><span>    logs[<span style=color:#e6db74>&#34;val_loss&#34;</span>] <span style=color:#f92672>=</span> loss_tracking_metric<span style=color:#f92672>.</span>result()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> logs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>val_dataset <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>Dataset<span style=color:#f92672>.</span>from_tensor_slices((val_images, val_labels))
</span></span><span style=display:flex><span>val_dataset <span style=color:#f92672>=</span> val_dataset<span style=color:#f92672>.</span>batch(<span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>reset_metrics()
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> inputs_batch, targets_batch <span style=color:#f92672>in</span> val_dataset:
</span></span><span style=display:flex><span>    logs <span style=color:#f92672>=</span> test_step(inputs_batch, targets_batch)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Evaluation results:&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> key, value <span style=color:#f92672>in</span> logs<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;...</span><span style=color:#e6db74>{</span>key<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>value<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h2 id=利用-tffunction-來加速>利用 tf.function 來加速<a hidden class=anchor aria-hidden=true href=#利用-tffunction-來加速>#</a></h2><ul><li>只要在要編譯的函式前加上 <code>@tf.function</code> 裝飾器就可以將 TensorFlow 程式碼編譯成運算圖(computation graph)。</li></ul><h2 id=搭配-fit-和自定義的訓練的迴圈>搭配 fit() 和自定義的訓練的迴圈<a hidden class=anchor aria-hidden=true href=#搭配-fit-和自定義的訓練的迴圈>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1. 將 optimizer 移到類別內部</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CustomModel</span>(keras<span style=color:#f92672>.</span>Model):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, inputs, outputs):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span><span style=color:#a6e22e>__init__</span>(inputs<span style=color:#f92672>=</span>inputs, outputs<span style=color:#f92672>=</span>outputs)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>loss_tracker <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>Mean(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;loss&#34;</span>)  <span style=color:#75715e># 2. 移到類別內</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>optimizer <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>RMSprop()  <span style=color:#75715e># 3. 加入 optimizer</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>loss_fn <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>losses<span style=color:#f92672>.</span>SparseCategoricalCrossentropy()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_step</span>(self, data):
</span></span><span style=display:flex><span>        inputs, targets <span style=color:#f92672>=</span> data
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>GradientTape() <span style=color:#66d9ef>as</span> tape:
</span></span><span style=display:flex><span>            predictions <span style=color:#f92672>=</span> self(inputs, training<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>            loss <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>loss_fn(targets, predictions)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        gradients <span style=color:#f92672>=</span> tape<span style=color:#f92672>.</span>gradient(loss, self<span style=color:#f92672>.</span>trainable_weights)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>optimizer<span style=color:#f92672>.</span>apply_gradients(zip(gradients, self<span style=color:#f92672>.</span>trainable_weights))  <span style=color:#75715e># 4. 使用 self.optimizer</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>loss_tracker<span style=color:#f92672>.</span>update_state(loss)  <span style=color:#75715e># 5. 使用 self.loss_tracker</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {<span style=color:#e6db74>&#34;loss&#34;</span>: self<span style=color:#f92672>.</span>loss_tracker<span style=color:#f92672>.</span>result()}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@property</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>metrics</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> [self<span style=color:#f92672>.</span>loss_tracker]  <span style=color:#75715e># 6. 使用 self.loss_trackerxqf</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立模型</span>
</span></span><span style=display:flex><span>inputs <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Input(shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>28</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>28</span>,))
</span></span><span style=display:flex><span>features <span style=color:#f92672>=</span> layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>512</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>)(inputs)
</span></span><span style=display:flex><span>features <span style=color:#f92672>=</span> layers<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>)(features)
</span></span><span style=display:flex><span>outputs <span style=color:#f92672>=</span> layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;softmax&#34;</span>)(features)
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> CustomModel(inputs<span style=color:#f92672>=</span>inputs, outputs<span style=color:#f92672>=</span>outputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile()  <span style=color:#75715e># 7. 移除 optimizer 參數</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(train_images, train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://intervalrain.github.io/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=https://intervalrain.github.io/ai/3_7/><span class=title>« 上一頁</span><br><span>[AI] 3-7. Keras API</span>
</a><a class=next href=https://intervalrain.github.io/ai/4_1/><span class=title>下一頁 »</span><br><span>[AI] 二元分類問題</span></a></nav><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://intervalrain.github.io/>Rain Hu's Workspace</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="複製";function s(){t.innerHTML="已複製！",setTimeout(()=>{t.innerHTML="複製"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>