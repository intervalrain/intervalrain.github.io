<!doctype html><html lang=zh-tw dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[AI] 提高普適化能力 | Rain Hu's Workspace</title>
<meta name=keywords content="AI"><meta name=description content="How to enhance the generalization ability of the model"><meta name=author content="Rain Hu"><link rel=canonical href=https://intervalrain.github.io/><meta name=google-site-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.662816b9df27c772d2b97c5f5f6bf4f2c5531051a330015f0ad4135736d0e56a.css integrity="sha256-ZigWud8nx3LSuXxfX2v08sVTEFGjMAFfCtQTVzbQ5Wo=" rel="preload stylesheet" as=style><link rel=icon href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=16x16 href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=32x32 href=https://intervalrain.github.io/images/rain.png><link rel=apple-touch-icon href=https://intervalrain.github.io/images/rain.png><link rel=mask-icon href=https://intervalrain.github.io/images/rain.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-tw href=https://intervalrain.github.io/ai/5_4/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script><script src=https://utteranc.es/client.js repo=intervalrain.github.io issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script><meta property="og:url" content="https://intervalrain.github.io/ai/5_4/"><meta property="og:site_name" content="Rain Hu's Workspace"><meta property="og:title" content="[AI] 提高普適化能力"><meta property="og:description" content="How to enhance the generalization ability of the model"><meta property="og:locale" content="zh-tw"><meta property="og:type" content="article"><meta property="article:section" content="ai"><meta property="article:published_time" content="2025-01-12T17:54:28+08:00"><meta property="article:modified_time" content="2025-01-12T17:54:28+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="[AI] 提高普適化能力"><meta name=twitter:description content="How to enhance the generalization ability of the model"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"[AI] 提高普適化能力","item":"https://intervalrain.github.io/ai/5_4/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[AI] 提高普適化能力","name":"[AI] 提高普適化能力","description":"How to enhance the generalization ability of the model","keywords":["AI"],"articleBody":"資料 如果要訓練出具備普適化的模型，那麼資料的重要性非常的大，若資料存在很大的不確定性(充滿雜訊)，或是任務本身是離散，缺乏連續變化關係，那麼深度學習將無法幫上忙。在收集資料時，有以下幾點重點： 資料量: 足夠的資料量才能對輸入空間進行密集採樣(特別是 boundary)，有足夠的資料才能讓樣本在流形空間中平滑的內插。就像是考試考超出範圍，學生無法用既有的知識來解題。 減少錯誤標示: 若資料有錯誤的 label，會導致模型的訓練結果不好。就像是老師教錯觀念，學生運用不對的觀念解題導致錯誤。 清理資料並處理缺失值: 若資料本身常出現缺失值，需要透過模型腦補，那也會導致模型訓練結果不好。就像老師教書時，沒有完整的教好觀念，導致學生自行腦補出錯的觀念。 特徵工程 在訓練模型前，若對資料本身有一定程度的理解，能對資料作一定程度的前處理，可以大大的降低訓練的成本並提升模型的準確度。\n以時鐘辨別作為案例，我們產生類似 mnist 的像素圖(10000 * 28 * 28)，並嘗試用不同的特徵來進行 training，來比較模型的成果。 我們可以嘗試使用三種不一樣的特徵來進行 training： 同 mnist，直接餵入像素圖。(即 shape=(28*28)) 使用時針與分針的卡氏座標。(即 shape=(4)) 例 (3.81, 7.48, 6.58, -9.06) 表示 (hr_x, hr_y, min_x, min_y) 使用時針與分針的極座標。(即 shape=(2)) 例 (2.67, 0.63) 表示 (hr_rad, min_rad) 由於我們透過特徵轉換，將原始資料轉換成更有效的資料，便可以增加訓練的效率。 CNN 透過 filter 與 max pooling 放大重要的圖形特徵，降維並保留重要的特徵來優化圖像的辨識，讓 model 自動發現關鍵的特徵。但在這個案例中，雖然有效，但浪費。 Early Stopping 過度訓練(overfit)是深度學習中最常遇到的問題，避免過度訓練的一個有效方法是 early stopping：\n提前終止訓練: 在驗證集的誤差開始增加時，提前結束訓練過程。就像補習班老師發現學生反覆練習同一類型題目，因為背 pattern 走火入魔前，反而失去靈活的思考，便及時停止練習題目。\n實作方式: 設定 patience 參數，當驗證集誤差連續超過設定次數都沒有改善時，便停止訓練並回傳最佳模型。\ncallback = tf.keras.callbacks.EarlyStopping( monitor='val_loss', # 監控驗證集損失 patience=7, # 容忍多少個 epoch 沒有改善 min_delta=1e-4, # 視為改善的最小變化量 mode='min', # 監控指標是越小越好 restore_best_weights=True # 回存最佳權重 ) model.fit( x_train, y_train, epochs=1000, validation_data=(x_val, y_val), callbacks=[callback] ) Regularization 正則化通過對模型權重加入懲罰項，限制模型的複雜度： L1 正則化: 添加權重絕對值的懲罰項，傾向產生稀疏的權重矩陣。 L2 正則化: 添加權重平方的懲罰項，傾向產生較小且分散的權重值。 就像老師要求學生用最簡單的方法解題，避免過度複雜的解法。 # L1 正則化 regularizer = tf.keras.regularizers.l1(l=0.01) # L2 正則化 regularizer = tf.keras.regularizers.l2(l=0.01) model = tf.keras.Sequential([ tf.keras.layers.Dense( units=512, kernel_regularizer=regularizer, activation='relu' ) ]) Dropout Dropout 是一種在訓練時隨機「關閉」一些神經元的技術： 原理: 每次訓練時隨機讓部分神經元停止工作，迫使網路學習多樣化的特徵表示。 效果: 相當於訓練多個不同的子網路並進行集成，減少過擬合。 就像讓學生在不同情境下解題，培養靈活運用知識的能力，而不是死記硬背。 model = tf.keras.Sequential([ tf.keras.layers.Dense(512, activation='relu'), tf.keras.layers.Dropout(0.5), # 50% 的神經元會被隨機關閉 tf.keras.layers.Dense(256, activation='relu'), tf.keras.layers.Dropout(0.3), # 30% 的神經元會被隨機關閉 tf.keras.layers.Dense(10, activation='softmax') ]) model.fit(x_train, y_train, epochs=100) model.evaluate(x_test, y_test) ","wordCount":"158","inLanguage":"zh-tw","datePublished":"2025-01-12T17:54:28+08:00","dateModified":"2025-01-12T17:54:28+08:00","author":{"@type":"Person","name":"Rain Hu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://intervalrain.github.io/ai/5_4/"},"publisher":{"@type":"Organization","name":"Rain Hu's Workspace","logo":{"@type":"ImageObject","url":"https://intervalrain.github.io/images/rain.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://intervalrain.github.io/ accesskey=h title="Rain Hu's Workspace (Alt + H)"><img src=https://intervalrain.github.io/images/rain.png alt aria-label=logo height=35>Rain Hu's Workspace</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://intervalrain.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://intervalrain.github.io/aboutme title="About me"><span>About me</span></a></li><li><a href=https://intervalrain.github.io/archives title=Archives><span>Archives</span></a></li><li><a href=https://intervalrain.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://intervalrain.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://intervalrain.github.io/csharp/csharp title=C#><span>C#</span></a></li><li><a href=https://intervalrain.github.io/csindex title=CS><span>CS</span></a></li><li><a href=https://intervalrain.github.io/leetcode title=LeetCode><span>LeetCode</span></a></li><li><a href=https://intervalrain.github.io/ai title=AI><span>AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://intervalrain.github.io/>首頁</a></div><h1 class="post-title entry-hint-parent">[AI] 提高普適化能力</h1><div class=post-description>How to enhance the generalization ability of the model</div><div class=post-meta><span title='2025-01-12 17:54:28 +0800 +0800'>January 12, 2025</span>&nbsp;·&nbsp;1 分鐘&nbsp;·&nbsp;Rain Hu&nbsp;|&nbsp;<a href=https://github.com/intervalrain/intervalrain.github.io/tree/main/content//AI/5_4.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目錄</span></summary><div class=inner><ul><li><a href=#%e8%b3%87%e6%96%99 aria-label=資料>資料</a></li><li><a href=#%e7%89%b9%e5%be%b5%e5%b7%a5%e7%a8%8b aria-label=特徵工程>特徵工程</a></li><li><a href=#early-stopping aria-label="Early Stopping">Early Stopping</a></li><li><a href=#regularization aria-label=Regularization>Regularization</a></li><li><a href=#dropout aria-label=Dropout>Dropout</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=資料>資料<a hidden class=anchor aria-hidden=true href=#資料>#</a></h1><ul><li>如果要訓練出具備普適化的模型，那麼資料的重要性非常的大，若資料存在很大的不確定性(充滿雜訊)，或是任務本身是離散，缺乏連續變化關係，那麼深度學習將無法幫上忙。在收集資料時，有以下幾點重點：<ul><li><strong>資料量</strong>: 足夠的資料量才能對輸入空間進行密集採樣(特別是 boundary)，有足夠的資料才能讓樣本在流形空間中平滑的內插。就像是考試考超出範圍，學生無法用既有的知識來解題。
<img alt=data_size loading=lazy src=/ai/AI/5_4/data_size.png></li><li><strong>減少錯誤標示</strong>: 若資料有錯誤的 label，會導致模型的訓練結果不好。就像是老師教錯觀念，學生運用不對的觀念解題導致錯誤。
<img alt=wrong_label loading=lazy src=/ai/AI/5_4/wrong_label.png></li><li><strong>清理資料並處理缺失值</strong>: 若資料本身常出現缺失值，需要透過模型腦補，那也會導致模型訓練結果不好。就像老師教書時，沒有完整的教好觀念，導致學生自行腦補出錯的觀念。
<img alt=wrong_label loading=lazy src=/ai/AI/5_4/missing_value.png></li></ul></li></ul><h1 id=特徵工程>特徵工程<a hidden class=anchor aria-hidden=true href=#特徵工程>#</a></h1><ul><li><p>在訓練模型前，若對資料本身有一定程度的理解，能對資料作一定程度的前處理，可以大大的降低訓練的成本並提升模型的準確度。</p></li><li><p>以時鐘辨別作為案例，我們產生類似 mnist 的像素圖(10000 * 28 * 28)，並嘗試用不同的特徵來進行 training，來比較模型的成果。
<img alt=clock_sample loading=lazy src=/ai/AI/5_4/clock_sample.png></p><ul><li>我們可以嘗試使用三種不一樣的特徵來進行 training：<ol><li>同 mnist，直接餵入像素圖。(即 shape=(28*28))</li><li>使用時針與分針的卡氏座標。(即 shape=(4))</li></ol><ul><li>例 (3.81, 7.48, 6.58, -9.06) 表示 (hr_x, hr_y, min_x, min_y)</li></ul><ol start=3><li>使用時針與分針的極座標。(即 shape=(2))</li></ol><ul><li>例 (2.67, 0.63) 表示 (hr_rad, min_rad)</li></ul></li><li>由於我們透過特徵轉換，將原始資料轉換成更有效的資料，便可以增加訓練的效率。</li><li>CNN 透過 filter 與 max pooling 放大重要的圖形特徵，降維並保留重要的特徵來優化圖像的辨識，讓 model 自動發現關鍵的特徵。但在這個案例中，雖然有效，但浪費。</li></ul><h1 id=early-stopping>Early Stopping<a hidden class=anchor aria-hidden=true href=#early-stopping>#</a></h1></li><li><p>過度訓練(overfit)是深度學習中最常遇到的問題，避免過度訓練的一個有效方法是 early stopping：</p><ul><li><p><strong>提前終止訓練</strong>: 在驗證集的誤差開始增加時，提前結束訓練過程。就像補習班老師發現學生反覆練習同一類型題目，因為背 pattern 走火入魔前，反而失去靈活的思考，便及時停止練習題目。</p></li><li><p><strong>實作方式</strong>: 設定 patience 參數，當驗證集誤差連續超過設定次數都沒有改善時，便停止訓練並回傳最佳模型。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>callback <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>callbacks<span style=color:#f92672>.</span>EarlyStopping(
</span></span><span style=display:flex><span>    monitor<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;val_loss&#39;</span>,       <span style=color:#75715e># 監控驗證集損失</span>
</span></span><span style=display:flex><span>    patience<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>,              <span style=color:#75715e># 容忍多少個 epoch 沒有改善</span>
</span></span><span style=display:flex><span>    min_delta<span style=color:#f92672>=</span><span style=color:#ae81ff>1e-4</span>,         <span style=color:#75715e># 視為改善的最小變化量</span>
</span></span><span style=display:flex><span>    mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;min&#39;</span>,             <span style=color:#75715e># 監控指標是越小越好</span>
</span></span><span style=display:flex><span>    restore_best_weights<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>  <span style=color:#75715e># 回存最佳權重</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(
</span></span><span style=display:flex><span>    x_train, 
</span></span><span style=display:flex><span>    y_train,
</span></span><span style=display:flex><span>    epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>,
</span></span><span style=display:flex><span>    validation_data<span style=color:#f92672>=</span>(x_val, y_val),
</span></span><span style=display:flex><span>    callbacks<span style=color:#f92672>=</span>[callback]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li></ul></li></ul><h1 id=regularization>Regularization<a hidden class=anchor aria-hidden=true href=#regularization>#</a></h1><ul><li>正則化通過對模型權重加入懲罰項，限制模型的複雜度：<ul><li><strong>L1 正則化</strong>: 添加權重絕對值的懲罰項，傾向產生稀疏的權重矩陣。</li><li><strong>L2 正則化</strong>: 添加權重平方的懲罰項，傾向產生較小且分散的權重值。</li><li>就像老師要求學生用最簡單的方法解題，避免過度複雜的解法。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>  <span style=color:#75715e># L1 正則化</span>
</span></span><span style=display:flex><span>  regularizer <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>regularizers<span style=color:#f92672>.</span>l1(l<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># L2 正則化</span>
</span></span><span style=display:flex><span>  regularizer <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>regularizers<span style=color:#f92672>.</span>l2(l<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>      tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(
</span></span><span style=display:flex><span>          units<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>,
</span></span><span style=display:flex><span>          kernel_regularizer<span style=color:#f92672>=</span>regularizer,
</span></span><span style=display:flex><span>          activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>
</span></span><span style=display:flex><span>      )
</span></span><span style=display:flex><span>  ])
</span></span></code></pre></div></li></ul><h1 id=dropout>Dropout<a hidden class=anchor aria-hidden=true href=#dropout>#</a></h1><ul><li>Dropout 是一種在訓練時隨機「關閉」一些神經元的技術：<ul><li><strong>原理</strong>: 每次訓練時隨機讓部分神經元停止工作，迫使網路學習多樣化的特徵表示。</li><li><strong>效果</strong>: 相當於訓練多個不同的子網路並進行集成，減少過擬合。</li><li>就像讓學生在不同情境下解題，培養靈活運用知識的能力，而不是死記硬背。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>  model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>      tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>512</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>      tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),  <span style=color:#75715e># 50% 的神經元會被隨機關閉</span>
</span></span><span style=display:flex><span>      tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>256</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>      tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.3</span>),  <span style=color:#75715e># 30% 的神經元會被隨機關閉</span>
</span></span><span style=display:flex><span>      tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;softmax&#39;</span>)
</span></span><span style=display:flex><span>  ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>fit(x_train, y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>)
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>evaluate(x_test, y_test)
</span></span></code></pre></div></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://intervalrain.github.io/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=https://intervalrain.github.io/ai/5_3/><span class=title>« 上一頁</span><br><span>[AI] 提升模型的表現</span>
</a><a class=next href=https://intervalrain.github.io/ai/5_5/><span class=title>下一頁 »</span><br><span>[AI] 機器學習的流程</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://intervalrain.github.io/>Rain Hu's Workspace</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="複製";function s(){t.innerHTML="已複製！",setTimeout(()=>{t.innerHTML="複製"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>