<!doctype html><html lang=zh-tw dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[AI] 2-1. 初試神經網路-手寫辨識 mnist | Rain Hu's Workspace</title><meta name=keywords content="AI"><meta name=description content="First trial for neural network using mnist"><meta name=author content="Rain Hu"><link rel=canonical href=https://intervalrain.github.io/><meta name=google-site-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0cefe5a1d95e3d0f0cce057d37c60cd238d1a4af825090f831a18f21671f621d.css integrity="sha256-DO/lodlePQ8MzgV9N8YM0jjRpK+CUJD4MaGPIWcfYh0=" rel="preload stylesheet" as=style><link rel=icon href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=16x16 href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=32x32 href=https://intervalrain.github.io/images/rain.png><link rel=apple-touch-icon href=https://intervalrain.github.io/images/rain.png><link rel=mask-icon href=https://intervalrain.github.io/images/rain.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-tw href=https://intervalrain.github.io/ai/2_1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script><script async src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script src=https://utteranc.es/client.js repo=intervalrain.github.io issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script><meta property="og:url" content="https://intervalrain.github.io/ai/2_1/"><meta property="og:site_name" content="Rain Hu's Workspace"><meta property="og:title" content="[AI] 2-1. 初試神經網路-手寫辨識 mnist"><meta property="og:description" content="First trial for neural network using mnist"><meta property="og:locale" content="zh-tw"><meta property="og:type" content="article"><meta property="article:section" content="ai"><meta property="article:published_time" content="2024-12-15T13:05:53+08:00"><meta property="article:modified_time" content="2024-12-15T13:05:53+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="[AI] 2-1. 初試神經網路-手寫辨識 mnist"><meta name=twitter:description content="First trial for neural network using mnist"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"[AI] 2-1. 初試神經網路-手寫辨識 mnist","item":"https://intervalrain.github.io/ai/2_1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[AI] 2-1. 初試神經網路-手寫辨識 mnist","name":"[AI] 2-1. 初試神經網路-手寫辨識 mnist","description":"First trial for neural network using mnist","keywords":["AI"],"articleBody":" MNIST 是經典的手寫數字圖片資料集，已經內建在 tensorflow 裡面，這個資料集可以相當於是深度學習的 “Hello World”，是由美國國家標準與技術研究院(National Institute of Standard and Technology) 所提供。 1. 認識 MNIST 資料集 透過 tensorflow 引入資料集 from tensorflow.keras.datasets import mnist (train_images, train_labels), (test_images, test_labels) = mnist.load_data() 查看資料的大小 train_images.shape len(train_labels) test_images.shape test_labels min(test_labels), max(test_labels) 結果 (60000, 28, 28) # 代表 train_images 是 60000 張 28*28 的圖片 60000 # 代表 train_labels 同樣也有 60000 份 (10000, 28, 28) # 代表 test_images 有 10000 張 28*28 的圖片 array([7, 2, 1, ..., 4, 5, 6], dtype=uint8) (0, 9) # 代表 test_labels 是 0-9 的數字，資料型別是 uint8 2. 神經網路架構 接下來的操作流程是： 將測資 train_images 和 train_labels 餵給神經網路 神經網路學習分類圖片，與每張圖片的標籤對比，分類錯誤就修正(學習) 最後對 test_images 進行預測，並驗證結果看是否與 test_labels 吻合 from tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Dense(512, activation=\"relu\") layers.Dense(10, activation=\"softmax\") ]) 組成神經網路的基本元件為層(layer)，一個層就是一個資料處理的模組。可以視之為資料的過濾器。具體而言，每一層都會從資料中萃取出特定的轉換或是表示法(representation)，這些特定的表示法會有助於解決某些問題。大多數深度學習模型會將許多層連接在一起，漸次執行資料萃取(data distillation)。 在範例中，神經網路由兩個密集層(Dense layers)緊密連接組成，密集層也稱為全連接(fully connected) 神經層。第二個密集層是有 10 個輸出的 softmax 層，最終會輸出 10 個機率評分的陣列，每個評分就是對應到每一個數字的機率。 model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) 為了讓神經網路接受訓練，還需要準備三個元件才能進行編譯。\n損失函數(loss function): 用來衡量神經網路在訓練資料上的表現，以及引導神經網路往正確的方向修正。 優化器(optimizer): 神經網路根據訓練資料與損失函數值來自行更新權重參數的機制 評量指標(metrics): 最後我們關心的是模型的準確度(accuracy)，即正確的比例。 \\( \\boxed{ \\begin{array}{ccccccc} \u0026\u0026 \\text{輸入資料 X} \u0026 \\\\ \u0026\u0026 \\downarrow \u0026 \\\\ \\red{\\boxed{\\text{權重’}}} \u0026 \\rightarrow \u0026 \\boxed{\\text{層(資料轉換)}} \\\\ \\red{\\uparrow} \u0026\u0026 \\downarrow \u0026 \\\\ \\red{\\boxed{\\text{權重’}}} \u0026 \\rightarrow \u0026 \\boxed{\\text{層(資料轉換)}} \\\\ \u0026\u0026 \\downarrow \u0026 \\\\ \\red{\\uparrow} \u0026\u0026 \\boxed{\\text{預測 Y’}}\\rightarrow \u0026 \\boxed{\\text{損失函數}} \u0026 \\leftarrow \u0026 \\boxed{\\text{標準答案 Y}} \\\\ \u0026\u0026\u0026 \\downarrow \u0026 \\\\ \\red{\\boxed{\\text{優化器}}} \u0026\u0026 \\red{\\leftarrow} \u0026 \\boxed{\\text{損失分數}} \\end{array} } \\)\ntrain_images = train_images.reshape((60000, 28 * 28)) train_images = train_images.astype('float32') / 255 test_images = test_images.reshape((10000, 28 * 28)) test_images = test_images.astype('float32') / 255 再進行訓練之前，需要將資料做正規化處理。在範例中，資料為 [0,255] 之間的像素值(uint8)並儲存在 (60000, 28,28) 的陣列中。我將轉換所有像素資料成 [0,1] 之間的 float32，並儲存在 (60000, 28*28) 的二軸陣列。 model.fit(train_images, train_labels, epochs=5, batch_size=128) 接下來就可以呼叫 fit() 來訓練模型了。\naccuracy 代表的是準確度。 loss 代表的是損失值，代表使用的損失函數所算出來的評估值。 Epoch 1/5 469/469 ━━━━━━━━━━━━━━━━━━━━ 6s 10ms/step - accuracy: 0.8717 - loss: 0.4605 Epoch 2/5 469/469 ━━━━━━━━━━━━━━━━━━━━ 6s 13ms/step - accuracy: 0.9655 - loss: 0.1179 Epoch 3/5 469/469 ━━━━━━━━━━━━━━━━━━━━ 9s 9ms/step - accuracy: 0.9788 - loss: 0.0720 Epoch 4/5 469/469 ━━━━━━━━━━━━━━━━━━━━ 6s 12ms/step - accuracy: 0.9857 - loss: 0.0490 Epoch 5/5 469/469 ━━━━━━━━━━━━━━━━━━━━ 4s 9ms/step - accuracy: 0.9904 - loss: 0.0354 \u003ckeras.src.callbacks.history.History at 0x7ae172cf8760\u003e 訓練完，我們接著可以用模型來預測測試資料。\ntest_digits = test_images[0:20] predictions = model.predict(test_digits) predictions.argmax(axis=1) # 列出每行中最大值的索引值 結果 array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]) 嘗試把手寫圖片畫出來，比較一下 import matplotlib.pyplot as plt n = 20 for i in range(n): plt.subplot(1, n, i+1) plt.imshow(test_images_pic[i], cmap='gray') plt.axis('off') plt.tight_layout() plt.show() 最後我們把模型拿來測試全部 10000 張測資，看一下準確度是多少 test_loss, test_acc = model.evaluate(test_images, test_labels) print(f'test_acc: {test_acc}') 結果 test_acc: 0.9810000061988831 代表正確率為 98.1% 比較訓練集的準確度為 0.9904，測試集的準確度為 0.981，這樣的差距稱為過度配適(overfitting)，意指模型對新資料的表現比訓練資料還要差。 3. 摘要 在本篇做了以下的事\n載入 mnist 資料集 用 Dense Layer 建構了一個神經網路 用 model.compile 來編譯神經網路，需要指定 opimizer, loss, metric 三個參數 對資料集做預處理 用 model.fit() 來訓練 用 model.predict() 來預測 用 model.evaluate 來評估模型表現 ","wordCount":"397","inLanguage":"zh-tw","datePublished":"2024-12-15T13:05:53+08:00","dateModified":"2024-12-15T13:05:53+08:00","author":{"@type":"Person","name":"Rain Hu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://intervalrain.github.io/ai/2_1/"},"publisher":{"@type":"Organization","name":"Rain Hu's Workspace","logo":{"@type":"ImageObject","url":"https://intervalrain.github.io/images/rain.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://intervalrain.github.io/ accesskey=h title="Rain Hu's Workspace (Alt + H)"><img src=https://intervalrain.github.io/images/rain.png alt aria-label=logo height=35>Rain Hu's Workspace</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://intervalrain.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://intervalrain.github.io/aboutme title="About me"><span>About me</span></a></li><li><a href=https://intervalrain.github.io/archives title=Archives><span>Archives</span></a></li><li><a href=https://intervalrain.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://intervalrain.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://intervalrain.github.io/csharp/csharp title=C#><span>C#</span></a></li><li><a href=https://intervalrain.github.io/csindex title=CS><span>CS</span></a></li><li><a href=https://intervalrain.github.io/leetcode title=LeetCode><span>LeetCode</span></a></li><li><a href=https://intervalrain.github.io/ai title=AI><span>AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://intervalrain.github.io/>首頁</a></div><h1 class="post-title entry-hint-parent">[AI] 2-1. 初試神經網路-手寫辨識 mnist</h1><div class=post-description>First trial for neural network using mnist</div><div class=post-meta><span title='2024-12-15 13:05:53 +0800 +0800'>December 15, 2024</span>&nbsp;·&nbsp;2 分鐘&nbsp;·&nbsp;Rain Hu&nbsp;|&nbsp;<a href=https://github.com/intervalrain/intervalrain.github.io/tree/main/content//AI/2_1.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目錄</span></summary><div class=inner><ul><li><a href=#1-%e8%aa%8d%e8%ad%98-mnist-%e8%b3%87%e6%96%99%e9%9b%86 aria-label="1. 認識 MNIST 資料集">1. 認識 MNIST 資料集</a></li><li><a href=#2-%e7%a5%9e%e7%b6%93%e7%b6%b2%e8%b7%af%e6%9e%b6%e6%a7%8b aria-label="2. 神經網路架構">2. 神經網路架構</a></li><li><a href=#3-%e6%91%98%e8%a6%81 aria-label="3. 摘要">3. 摘要</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><ul><li>MNIST 是經典的手寫數字圖片資料集，已經內建在 tensorflow 裡面，這個資料集可以相當於是深度學習的 &ldquo;Hello World&rdquo;，是由美國國家標準與技術研究院(National Institute of Standard and Technology) 所提供。</li></ul><h2 id=1-認識-mnist-資料集>1. 認識 MNIST 資料集<a hidden class=anchor aria-hidden=true href=#1-認識-mnist-資料集>#</a></h2><ul><li>透過 tensorflow 引入資料集</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> mnist
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(train_images, train_labels), (test_images, test_labels) <span style=color:#f92672>=</span> mnist<span style=color:#f92672>.</span>load_data()
</span></span></code></pre></div><ul><li>查看資料的大小</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>train_images<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>len(train_labels)
</span></span><span style=display:flex><span>test_images<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>test_labels
</span></span><span style=display:flex><span>min(test_labels), max(test_labels)
</span></span></code></pre></div><details><summary>結果</summary><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>(<span style=color:#ae81ff>60000</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>)     <span style=color:#75715e># 代表 train_images 是 60000 張 28*28 的圖片 </span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>60000</span>               <span style=color:#75715e># 代表 train_labels 同樣也有 60000 份</span>
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>10000</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>)     <span style=color:#75715e># 代表 test_images 有 10000 張 28*28 的圖片</span>
</span></span><span style=display:flex><span>array([<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, <span style=color:#f92672>...</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>6</span>], dtype<span style=color:#f92672>=</span>uint8)
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>9</span>)              <span style=color:#75715e># 代表 test_labels 是 0-9 的數字，資料型別是 uint8</span>
</span></span></code></pre></div></details><h2 id=2-神經網路架構>2. 神經網路架構<a hidden class=anchor aria-hidden=true href=#2-神經網路架構>#</a></h2><ul><li>接下來的操作流程是：<ol><li>將測資 <code>train_images</code> 和 <code>train_labels</code> 餵給神經網路</li><li>神經網路學習分類圖片，與每張圖片的標籤對比，分類錯誤就修正(學習)</li><li>最後對 <code>test_images</code> 進行預測，並驗證結果看是否與 <code>test_labels</code> 吻合</li></ol></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>512</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>)
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;softmax&#34;</span>)
</span></span><span style=display:flex><span>])
</span></span></code></pre></div><ul><li>組成神經網路的基本元件為<strong>層(layer)</strong>，一個層就是一個資料處理的模組。可以視之為資料的過濾器。具體而言，每一層都會從資料中萃取出特定的轉換或是表示法(representation)，這些特定的表示法會有助於解決某些問題。大多數深度學習模型會將許多層連接在一起，漸次執行<strong>資料萃取(data distillation)</strong>。</li><li>在範例中，神經網路由兩個密集層(Dense layers)緊密連接組成，密集層也稱為<strong>全連接(fully connected)</strong> 神經層。第二個密集層是有 10 個輸出的 softmax 層，最終會輸出 10 個機率評分的陣列，每個評分就是對應到每一個數字的機率。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>,
</span></span><span style=display:flex><span>    loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sparse_categorical_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>    metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span></code></pre></div><ul><li><p>為了讓神經網路接受訓練，還需要準備三個元件才能進行編譯。</p><ol><li><strong>損失函數(loss function)</strong>: 用來衡量神經網路在訓練資料上的表現，以及引導神經網路往正確的方向修正。</li><li><strong>優化器(optimizer)</strong>: 神經網路根據訓練資料與損失函數值來自行更新權重參數的機制</li><li><strong>評量指標(metrics)</strong>: 最後我們關心的是模型的準確度(accuracy)，即正確的比例。</li></ol><p>\(
\boxed{
\begin{array}{ccccccc}
&& \text{輸入資料 X} & \\
&& \downarrow & \\
\red{\boxed{\text{權重&rsquo;}}} & \rightarrow & \boxed{\text{層(資料轉換)}} \\
\red{\uparrow} && \downarrow & \\
\red{\boxed{\text{權重&rsquo;}}} & \rightarrow & \boxed{\text{層(資料轉換)}} \\
&& \downarrow & \\
\red{\uparrow} && \boxed{\text{預測 Y&rsquo;}}\rightarrow & \boxed{\text{損失函數}} & \leftarrow & \boxed{\text{標準答案 Y}} \\
&&& \downarrow & \\
\red{\boxed{\text{優化器}}} && \red{\leftarrow} & \boxed{\text{損失分數}}
\end{array}
}
\)</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>60000</span>, <span style=color:#ae81ff>28</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;float32&#39;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>test_images <span style=color:#f92672>=</span> test_images<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>10000</span>, <span style=color:#ae81ff>28</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>test_images <span style=color:#f92672>=</span> test_images<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;float32&#39;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255</span>
</span></span></code></pre></div><ul><li>再進行訓練之前，需要將資料做正規化處理。在範例中，資料為 [0,255] 之間的像素值(uint8)並儲存在 (60000, 28,28) 的陣列中。我將轉換所有像素資料成 [0,1] 之間的 float32，並儲存在 (60000, 28*28) 的二軸陣列。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(train_images, train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>)
</span></span></code></pre></div><ul><li><p>接下來就可以呼叫 <code>fit()</code> 來訓練模型了。</p><ul><li>accuracy 代表的是準確度。</li><li>loss 代表的是損失值，代表使用的損失函數所算出來的評估值。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>Epoch <span style=color:#ae81ff>1</span><span style=color:#f92672>/</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>469</span><span style=color:#f92672>/</span><span style=color:#ae81ff>469</span> <span style=color:#960050;background-color:#1e0010>━━━━━━━━━━━━━━━━━━━━</span> <span style=color:#ae81ff>6</span>s <span style=color:#ae81ff>10</span>ms<span style=color:#f92672>/</span>step <span style=color:#f92672>-</span> accuracy: <span style=color:#ae81ff>0.8717</span> <span style=color:#f92672>-</span> loss: <span style=color:#ae81ff>0.4605</span>
</span></span><span style=display:flex><span>Epoch <span style=color:#ae81ff>2</span><span style=color:#f92672>/</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>469</span><span style=color:#f92672>/</span><span style=color:#ae81ff>469</span> <span style=color:#960050;background-color:#1e0010>━━━━━━━━━━━━━━━━━━━━</span> <span style=color:#ae81ff>6</span>s <span style=color:#ae81ff>13</span>ms<span style=color:#f92672>/</span>step <span style=color:#f92672>-</span> accuracy: <span style=color:#ae81ff>0.9655</span> <span style=color:#f92672>-</span> loss: <span style=color:#ae81ff>0.1179</span>
</span></span><span style=display:flex><span>Epoch <span style=color:#ae81ff>3</span><span style=color:#f92672>/</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>469</span><span style=color:#f92672>/</span><span style=color:#ae81ff>469</span> <span style=color:#960050;background-color:#1e0010>━━━━━━━━━━━━━━━━━━━━</span> <span style=color:#ae81ff>9</span>s <span style=color:#ae81ff>9</span>ms<span style=color:#f92672>/</span>step <span style=color:#f92672>-</span> accuracy: <span style=color:#ae81ff>0.9788</span> <span style=color:#f92672>-</span> loss: <span style=color:#ae81ff>0.0720</span>
</span></span><span style=display:flex><span>Epoch <span style=color:#ae81ff>4</span><span style=color:#f92672>/</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>469</span><span style=color:#f92672>/</span><span style=color:#ae81ff>469</span> <span style=color:#960050;background-color:#1e0010>━━━━━━━━━━━━━━━━━━━━</span> <span style=color:#ae81ff>6</span>s <span style=color:#ae81ff>12</span>ms<span style=color:#f92672>/</span>step <span style=color:#f92672>-</span> accuracy: <span style=color:#ae81ff>0.9857</span> <span style=color:#f92672>-</span> loss: <span style=color:#ae81ff>0.0490</span>
</span></span><span style=display:flex><span>Epoch <span style=color:#ae81ff>5</span><span style=color:#f92672>/</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>469</span><span style=color:#f92672>/</span><span style=color:#ae81ff>469</span> <span style=color:#960050;background-color:#1e0010>━━━━━━━━━━━━━━━━━━━━</span> <span style=color:#ae81ff>4</span>s <span style=color:#ae81ff>9</span>ms<span style=color:#f92672>/</span>step <span style=color:#f92672>-</span> accuracy: <span style=color:#ae81ff>0.9904</span> <span style=color:#f92672>-</span> loss: <span style=color:#ae81ff>0.0354</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;</span>keras<span style=color:#f92672>.</span>src<span style=color:#f92672>.</span>callbacks<span style=color:#f92672>.</span>history<span style=color:#f92672>.</span>History at <span style=color:#ae81ff>0x7ae172cf8760</span><span style=color:#f92672>&gt;</span>
</span></span></code></pre></div></li><li><p>訓練完，我們接著可以用模型來預測測試資料。</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>test_digits <span style=color:#f92672>=</span> test_images[<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>20</span>]
</span></span><span style=display:flex><span>predictions <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(test_digits)
</span></span><span style=display:flex><span>predictions<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)   <span style=color:#75715e># 列出每行中最大值的索引值</span>
</span></span></code></pre></div><details><summary>結果</summary><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>array([<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>])
</span></span></code></pre></div><ul><li>嘗試把手寫圖片畫出來，比較一下</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>n <span style=color:#f92672>=</span> <span style=color:#ae81ff>20</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(n):
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, n, i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(test_images_pic[i], cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img alt=mnist_20 loading=lazy src=/ai/AI/2_1/mnist_20.png></details></p><ul><li>最後我們把模型拿來測試全部 10000 張測資，看一下準確度是多少</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>test_loss, test_acc <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>evaluate(test_images, test_labels)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;test_acc: </span><span style=color:#e6db74>{</span>test_acc<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span></code></pre></div><details><summary>結果</summary><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>test_acc: <span style=color:#ae81ff>0.9810000061988831</span>
</span></span></code></pre></div><ul><li>代表正確率為 98.1%</details></li><li>比較訓練集的準確度為 0.9904，測試集的準確度為 0.981，這樣的差距稱為<strong>過度配適(overfitting)</strong>，意指模型對新資料的表現比訓練資料還要差。</li></ul><h2 id=3-摘要>3. 摘要<a hidden class=anchor aria-hidden=true href=#3-摘要>#</a></h2><p>在本篇做了以下的事</p><ol><li>載入 mnist 資料集</li><li>用 Dense Layer 建構了一個神經網路</li><li>用 model.compile 來編譯神經網路，需要指定 opimizer, loss, metric 三個參數</li><li>對資料集做預處理</li><li>用 model.fit() 來訓練</li><li>用 model.predict() 來預測</li><li>用 model.evaluate 來評估模型表現</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://intervalrain.github.io/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=https://intervalrain.github.io/ai/1_3/><span class=title>« 上一頁</span><br><span>[AI] 1-3. 深度學習的發展</span>
</a><a class=next href=https://intervalrain.github.io/ai/2_2/><span class=title>下一頁 »</span><br><span>[AI] 2-2. 張量 Tensor</span></a></nav><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://intervalrain.github.io/>Rain Hu's Workspace</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="複製";function s(){t.innerHTML="已複製！",setTimeout(()=>{t.innerHTML="複製"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>