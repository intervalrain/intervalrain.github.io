<!doctype html><html lang=zh-tw dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[AI] 普適化 | Rain Hu's Workspace</title><meta name=keywords content="AI"><meta name=description content="Introduction to generalization"><meta name=author content="Rain Hu"><link rel=canonical href=https://intervalrain.github.io/><meta name=google-site-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.4c6c0beaf1dfe52cd0f712a5896ac127e66fd064cfc598e04750f496d470699e.css integrity="sha256-TGwL6vHf5SzQ9xKliWrBJ+Zv0GTPxZjgR1D0ltRwaZ4=" rel="preload stylesheet" as=style><link rel=icon href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=16x16 href=https://intervalrain.github.io/images/rain.png><link rel=icon type=image/png sizes=32x32 href=https://intervalrain.github.io/images/rain.png><link rel=apple-touch-icon href=https://intervalrain.github.io/images/rain.png><link rel=mask-icon href=https://intervalrain.github.io/images/rain.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-tw href=https://intervalrain.github.io/ai/5_1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script><script src=https://utteranc.es/client.js repo=intervalrain.github.io issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script><meta property="og:url" content="https://intervalrain.github.io/ai/5_1/"><meta property="og:site_name" content="Rain Hu's Workspace"><meta property="og:title" content="[AI] 普適化"><meta property="og:description" content="Introduction to generalization"><meta property="og:locale" content="zh-tw"><meta property="og:type" content="article"><meta property="article:section" content="ai"><meta property="article:published_time" content="2025-01-12T17:52:09+08:00"><meta property="article:modified_time" content="2025-01-12T17:52:09+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="[AI] 普適化"><meta name=twitter:description content="Introduction to generalization"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"[AI] 普適化","item":"https://intervalrain.github.io/ai/5_1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[AI] 普適化","name":"[AI] 普適化","description":"Introduction to generalization","keywords":["AI"],"articleBody":" 機器學習最重要的兩件事是：\n準確的模型評估 訓練次數與普適化之間的平衡 普適化(generalization) 普適化是機器學習的終極目標，什麼是普適化呢？首先要先解釋是什麼低度擬合(underfitting) 與 過度擬合(overfitting)。 觀察下方的圖，訓練集與驗證集在訓練初期，損失值都穩定下降，此時稱為 underfitting，代表神經網路尚未學習到資料中的共同特徵。經過一定時間後，驗證指標會開始停滯並開始變差，這代表模型開始發生 overfitting，代表模型已經額外學習了一些只有訓練集中的特徵，進而可能在面對新資料時造成干擾。而 穩健擬合(robust fit) 是 underfitting 與 overfitting 之間的點，代表最佳的 epochs。 下圖的黑線與就是 robust fit 的表現，綠線是 overfitting 的表現。 可以看到綠線在訓練集有很好的表現，但可能會在新的資料點進入時，有錯誤的判斷。 普適化就是找到一個面對所有資料都能有穩定且好的表現的模型。 overfitting overfitting 容易發生在 具有雜訊的資料 具有罕見特徵 標示錯誤的資料 如果訓練過程，模型針對這些離群值(outlier)進行學習，普適化表現自然會下降。 模糊特徵 然後並非所有雜訊都是由不準確性(特徵模糊/標示錯誤)產生的，當處理的問題本身就具備不確定性或模棱兩可時，就算是字跡清晰、標籤正確也可能是雜訊，特別是一些沒有明確界線的特徵。 就像是下面的三杯一樣的水，由不同的人來 label，也會 label 出不一樣的答案。 最有感的就是問卷量表，客戶滿意度 (CSAT) 調查問卷通常分為 1 (非常不滿意) 到 5 分 (非常滿意) 。每個人對於滿意度的給分都不一致，所以就容易產生差異。 穩健的模型會忽略訓練資料中個別的資料點，從眾數著眼。 罕見特徵(rare feature)與虛假關聯(spurious correlation) 罕見特徵: 通常是樣本中出現頻率極低的特徵，可能具有高辨識度或影響力，但也可能是噪音，需要小心解讀。\n事故發生的地點是某條高速公路上極少使用的臨時匝道。 事故發生時段是凌晨2點到3點，且伴隨濃霧天氣。 涉事車輛是一輛載有易燃化學品的大型貨車，並與一輛滿載乘客的大巴相撞。 如何影響機器學習： 特徵稀疏性： 這些罕見的特徵組合在訓練數據中可能只出現過1-2次，但其後果卻極為嚴重（多人傷亡），模型可能過度強調這些罕見情況作為高危因素。 過擬合風險： 如果模型只根據這些少量案例進行學習，可能無法有效處理未見過的場景（如不同的道路或車輛組合）。 虛假關聯: 則是數據之間表面上有相關性，但實際上缺乏因果關係，可能由於第三因素驅動或純粹的巧合。\n冰淇淋銷量與溺水事件： 描述：夏季冰淇淋銷量與溺水事件呈現高度正相關。 原因：兩者都與溫度升高相關，並非冰淇淋銷量導致溺水事件增加。 接下來來做一個實驗，我們在每一張數字中擴充維度，分別擴充 noise 與 zeros from tensorflow.keras.datasets import mnist import numpy as np (train_images, train_labels), (test_images, test_labels) = mnist.load_data() train_images = train_images.reshape((60000, 28*28)) train_images = train_images.astype(\"float32\") / 255 train_images_with_noise = np.concatenate( [train_images, np.random.random((len(train_images), 784))], axis=1 ) train_images_with_zeros = np.concatenate( [train_images, np.zeros((len(train_images), 784))], axis=1 ) 接著我們用這兩個資料集來進行 training，來觀察訓練後的結果： from tensorflow import keras from tensorflow.keras import layers def build_model(): model = keras.Sequential([ layers.Dense(512, activation=\"relu\"), layers.Dense(10, activation=\"softmax\") ]) model.compile( optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) return model model = build_model() history_noise = model.fit(train_images_with_noise, train_labels, epochs=10, batch_size=128, validation_split=0.2) history_zeros = model.fit(train_images_with_zeros, train_labels, epochs=10, batch_size=128, validation_split=0.2) 畫出損失曲線 import matplotlib.pyplot as plt val_acc_noise = history_noise.history[\"val_accuracy\"] val_acc_zeros = history_zeros.history[\"val_accurarc\"] epochs = range(1, 11) plt.plot(epochs, val_acc_noise, \"b-\", label=\"data with noise\") plt.plot(epochs, val_acc_zeros, \"r-\", label=\"data with zeros\") plt.title(\"Effect of noise channels on validtaion accuracy\") plt.xlabel(\"Epochs\") plt.ylabel(\"Validation accuracy\") plt.legend() 可見兩組資料擁有相同的有效特徵資訊，但所訓練出來的模型在驗證準確度卻有明顯的差異，這差距來自於虛假關聯：但加入的雜訊愈多，準確度就會愈低。 雜訊幾乎都會造成 overfitting，故若不確定各種特徵是有用或無用時，通常要在訓練前進行特徵挑選(feature selection)。例如先前在 IMDB 資料，便時採用前 10000 個常用字。 常用的方法還包括特量每個特徵對於任務關聯性的量測，如特徵與標籤之間的 MI(mutual information) 分數，只保留分數在一定門閾值以上的特徵，用以過濾雜訊。 普適化的本質 事實上，只要模型具備足夠的學習能力，便可以持續訓練到能夠擬合任何的資料。 我們可以做一個實驗，將 mnist 的資料集的標籤打亂來進行訓練，此時圖片中的數字已與標籤無關聯，但訓練的失曲線仍會隨著訓練推進而持續下降。 from tensorflow import keras from tensorflow.keras import layers from tensorflow.keras.datasets import mnist import numpy as np (train_images, train_labels), _ = mnist.load_data() train_images = train_images.reshape((60000, 28*28)) train_images = train_images.astype(\"float32\")/255 random_train_labels = train_labels[:] np.random.shuffle(random_train_labels) model = keras.models.Sequential([ layers.Dense(512, activation=\"relu\"), layers.Dense(10, activation=\"softmax\") ]) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) history = model.fit(train_images, random_train_labels, epochs=100,batch_size=128,validation_split=0.2) import matplotlib.pyplot as plt loss = history.history['loss'] val_loss = history.history['val_loss'] epochs = range(1, len(loss) + 1) plt.plot(epochs, loss, 'bo', label='Training loss') plt.plot(epochs, val_loss, 'b', label='Validation loss') plt.title('Training and validation loss') plt.xlabel('Epochs') plt.ylabel('Loss') plt.legend() plt.show() 代表只要訓練次數夠多，終究能擬合訓練資料，就像是 dictionary 一樣，輸入與標籤就猶如字典的 key 與 value 一樣。 流形假說(manifold hypothesis) 真實世界的高維數據通常位於低維流形(manifold)上，這些數據點雖然存在於高維空間，但實際上具有更低的內在維度。 以 MNIST 為例，雖然每張圖片是 28×28=784 維的數據，但實際上所有手寫數字圖片大致分布在一個低維流形上 簡單想像你在玩一個猜拳的遊戲(剪刀、石頭、布)： 高維空間的概念 如果你用相機拍下出拳的手勢，每張照片可能是 1000×1000 像素，這代表每張照片在數學上是個 100 萬維的數據點，但實際上，手勢只有剪刀、石頭、布三種可能。 流形的概念 雖然照片是高維的，但手勢的變化是有限的，你可以慢慢從剪刀變成石頭，手指會沿著某個固定的軌跡彎曲，這個軌跡就像是一條\"路徑\"，這就是所謂的流形。 流形概念例子 import tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.datasets import mnist # 載入 MNIST 數據 (x_train, y_train), _ = mnist.load_data() x_train = x_train.astype('float32') / 255. # 找出數字 1 和 7 的例子 digit_1 = x_train[y_train == 1][0] digit_7 = x_train[y_train == 7][0] # 創建中間過渡圖片 steps = 5 transitions = [] for i in range(steps): alpha = i / (steps-1) # 簡單的線性混合 mixed = digit_1 * (1-alpha) + digit_7 * alpha transitions.append(mixed) # 顯示結果 plt.figure(figsize=(12, 3)) for i in range(steps): plt.subplot(1, steps, i+1) plt.imshow(transitions[i], cmap='gray') plt.axis('off') plt.suptitle('transition of number 1 to 7') plt.show() 以內插法作為普適化的基礎 深度學習的普適化能力，很大程度上依賴於模型能夠在訓練數據的流形上進行合理的內插。讓我們通過實驗來比較流形內插和線性內插的差異： 內插法程式 import tensorflow as tf from tensorflow.keras.datasets import mnist import numpy as np import matplotlib.pyplot as plt # 載入 MNIST 數據集 (x_train, y_train), _ = mnist.load_data() x_train = x_train.astype('float32') / 255. x_train_reshaped = x_train.reshape(-1, 28, 28, 1) # 建立編碼器 encoder_input = tf.keras.Input(shape=(28, 28, 1)) x = tf.keras.layers.Flatten()(encoder_input) x = tf.keras.layers.Dense(128, activation='relu')(x) x = tf.keras.layers.Dense(64, activation='relu')(x) latent = tf.keras.layers.Dense(32, activation='relu')(x) encoder = tf.keras.Model(encoder_input, latent, name='encoder') # 建立解碼器 decoder_input = tf.keras.Input(shape=(32,)) x = tf.keras.layers.Dense(64, activation='relu')(decoder_input) x = tf.keras.layers.Dense(128, activation='relu')(x) x = tf.keras.layers.Dense(784, activation='sigmoid')(x) decoder_output = tf.keras.layers.Reshape((28, 28, 1))(x) decoder = tf.keras.Model(decoder_input, decoder_output, name='decoder') # 建立完整的自編碼器 autoencoder_input = tf.keras.Input(shape=(28, 28, 1)) encoded = encoder(autoencoder_input) decoded = decoder(encoded) autoencoder = tf.keras.Model(autoencoder_input, decoded, name='autoencoder') # 編譯和訓練 autoencoder.compile(optimizer='adam', loss='binary_crossentropy') history = autoencoder.fit(x_train_reshaped, x_train_reshaped, epochs=20, batch_size=256, shuffle=True, validation_split=0.2) # 選擇兩張不同的數字圖片 img1 = x_train_reshaped[y_train == 2][0:1] # 選擇一個 2 img2 = x_train_reshaped[y_train == 7][0:1] # 選擇一個 7 # 生成線性內插 def linear_interpolation(img1, img2, num_steps=5): alphas = np.linspace(0, 1, num_steps) images = [] for alpha in alphas: interpolated = img1 * (1 - alpha) + img2 * alpha images.append(interpolated[0]) return np.array(images) # 生成流形內插 def manifold_interpolation(img1, img2, num_steps=5): # 獲取潛在表示 latent1 = encoder.predict(img1) latent2 = encoder.predict(img2) # 在潛在空間中內插 alphas = np.linspace(0, 1, num_steps) images = [] for alpha in alphas: interpolated_latent = latent1 * (1 - alpha) + latent2 * alpha # 使用解碼器重建圖片 decoded_img = decoder.predict(interpolated_latent) images.append(decoded_img[0]) return np.array(images) # 生成內插序列 linear_imgs = linear_interpolation(img1, img2) manifold_imgs = manifold_interpolation(img1, img2) # 顯示結果 plt.figure(figsize=(15, 6)) # 顯示線性內插 plt.subplot(2, 1, 1) plt.title('linear interpolation') for i in range(5): plt.subplot(2, 5, i + 1) plt.imshow(linear_imgs[i].reshape(28, 28), cmap='gray') plt.axis('off') # 顯示流形內插 plt.subplot(2, 1, 2) plt.title('manifold interpolation') for i in range(5): plt.subplot(2, 5, i + 6) plt.imshow(manifold_imgs[i].reshape(28, 28), cmap='gray') plt.axis('off') plt.tight_layout() plt.show() 換言之，因為新的資料可以透過現有的資料點內插而得，代表我們可以將新資料點連結到流形上相近的其它點，進而理解這些從未見過的資料點。也就是說我們可以靠空間的有限樣本來理解空間的整體性，做法是透過內插法來填滿其中的空白。以下是我的想像示意圖。 為何深度學習能運作 流形假說幫助我們理解為什麼深度學習能夠有效運作：\n流形學習：深度學習模型通過多層結構，逐漸學習數據的內在流形結構。 維度降低：神經網絡的中間層實際上在執行非線性維度降低，將高維輸入映射到更有意義的低維表示。 連續變化：在流形上的內插產生的是連續、平滑的變化，而不是簡單的線性混合： 線性內插：直接在像素空間中進行混合，可能產生不自然的中間狀態 流形內插：在學習到的流形空間中進行內插，產生的中間狀態更符合實際數據分布 歸納能力：模型的普適化能力很大程度上來自於它能夠在流形上進行合理的內插，而不是簡單地記住訓練數據。 這個實驗展示了為什麼簡單的線性內插會產生模糊或不自然的結果，而流形內插能產生更真實的過渡狀態。這也說明了深度學習模型不僅僅是在記憶數據，而是真正學習到了數據的內在結構。\n訓練資料的處理 儘管深度學習適合流形學習(manifold learning)，但普適化能力主要還是取決於資料的自然結構，而非模型的特性。只有當資料流形中的點可以內插，才有可能進行普適化。資料中的特徵愈清晰、愈沒有雜訊，普適化的能力才會愈好。這是因為輸入空間變得更簡單且有著更好的結構。\n故如果要提升普適化表現，資料篩選(data curation)和特徵工程(feature engineering)就尤為重要。\n以下同樣也是我的想像示意圖 模型若要表現良好，最好可以在輸入空間中密集抽樣(dense sampling)，並用抽樣出的資料來訓練模型。所謂密集抽樣是指訓練資料應該密集地涵蓋整個輸入空間的流形附近，特別是決策邊界附近 若想要模型表示得好，就得提供更多或更多的資料，那麼輸入資料的流形可以覆蓋更多、更密集的範圍，使得普適化能力更好。由於模型只能單純地在訓練樣本間進行內插，因此我們要讓模型可以透過簡單正確地內插，這一切將取決於模型的設計架構與訓練的資料。\n當無法取得更多資料時，我們能做的就是調降模型所能容納的資訊，或是在模型的擬合曲線上加入一些限制。讓模型只能記憶很有限或常見的樣態，在優化過程中強迫模型專注於最突出的樣態，這樣就有可能提升普適化能力。這種避免 overfitting 的方法叫作常規化(regularization) ","wordCount":"711","inLanguage":"zh-tw","datePublished":"2025-01-12T17:52:09+08:00","dateModified":"2025-01-12T17:52:09+08:00","author":{"@type":"Person","name":"Rain Hu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://intervalrain.github.io/ai/5_1/"},"publisher":{"@type":"Organization","name":"Rain Hu's Workspace","logo":{"@type":"ImageObject","url":"https://intervalrain.github.io/images/rain.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://intervalrain.github.io/ accesskey=h title="Rain Hu's Workspace (Alt + H)"><img src=https://intervalrain.github.io/images/rain.png alt aria-label=logo height=35>Rain Hu's Workspace</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://intervalrain.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://intervalrain.github.io/aboutme title="About me"><span>About me</span></a></li><li><a href=https://intervalrain.github.io/archives title=Archives><span>Archives</span></a></li><li><a href=https://intervalrain.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://intervalrain.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://intervalrain.github.io/csharp/csharp title=C#><span>C#</span></a></li><li><a href=https://intervalrain.github.io/csindex title=CS><span>CS</span></a></li><li><a href=https://intervalrain.github.io/leetcode title=LeetCode><span>LeetCode</span></a></li><li><a href=https://intervalrain.github.io/ai title=AI><span>AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://intervalrain.github.io/>首頁</a></div><h1 class="post-title entry-hint-parent">[AI] 普適化</h1><div class=post-description>Introduction to generalization</div><div class=post-meta><span title='2025-01-12 17:52:09 +0800 +0800'>January 12, 2025</span>&nbsp;·&nbsp;4 分鐘&nbsp;·&nbsp;Rain Hu&nbsp;|&nbsp;<a href=https://github.com/intervalrain/intervalrain.github.io/tree/main/content//AI/5_1.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目錄</span></summary><div class=inner><ul><li><a href=#%e6%99%ae%e9%81%a9%e5%8c%96generalization aria-label=普適化(generalization)>普適化(generalization)</a><ul><li><a href=#overfitting aria-label=overfitting>overfitting</a></li><li><a href=#%e6%a8%a1%e7%b3%8a%e7%89%b9%e5%be%b5 aria-label=模糊特徵>模糊特徵</a></li><li><a href=#%e7%bd%95%e8%a6%8b%e7%89%b9%e5%be%b5rare-feature%e8%88%87%e8%99%9b%e5%81%87%e9%97%9c%e8%81%afspurious-correlation aria-label="罕見特徵(rare feature)與虛假關聯(spurious correlation)">罕見特徵(rare feature)與虛假關聯(spurious correlation)</a></li></ul></li><li><a href=#%e6%99%ae%e9%81%a9%e5%8c%96%e7%9a%84%e6%9c%ac%e8%b3%aa aria-label=普適化的本質>普適化的本質</a><ul><li><a href=#%e6%b5%81%e5%bd%a2%e5%81%87%e8%aa%aamanifold-hypothesis aria-label="流形假說(manifold hypothesis)">流形假說(manifold hypothesis)</a></li><li><a href=#%e4%bb%a5%e5%85%a7%e6%8f%92%e6%b3%95%e4%bd%9c%e7%82%ba%e6%99%ae%e9%81%a9%e5%8c%96%e7%9a%84%e5%9f%ba%e7%a4%8e aria-label=以內插法作為普適化的基礎>以內插法作為普適化的基礎</a></li><li><a href=#%e7%82%ba%e4%bd%95%e6%b7%b1%e5%ba%a6%e5%ad%b8%e7%bf%92%e8%83%bd%e9%81%8b%e4%bd%9c aria-label=為何深度學習能運作>為何深度學習能運作</a></li><li><a href=#%e8%a8%93%e7%b7%b4%e8%b3%87%e6%96%99%e7%9a%84%e8%99%95%e7%90%86 aria-label=訓練資料的處理>訓練資料的處理</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><blockquote><p>機器學習最重要的兩件事是：</p><ol><li>準確的模型評估</li><li>訓練次數與普適化之間的平衡</li></ol></blockquote><h2 id=普適化generalization>普適化(generalization)<a hidden class=anchor aria-hidden=true href=#普適化generalization>#</a></h2><ul><li>普適化是機器學習的終極目標，什麼是普適化呢？首先要先解釋是什麼<strong>低度擬合(underfitting)</strong> 與 <strong>過度擬合(overfitting)</strong>。<ul><li>觀察下方的圖，訓練集與驗證集在訓練初期，損失值都穩定下降，此時稱為 underfitting，代表神經網路尚未學習到資料中的共同特徵。經過一定時間後，驗證指標會開始停滯並開始變差，這代表模型開始發生 overfitting，代表模型已經額外學習了一些只有訓練集中的特徵，進而可能在面對新資料時造成干擾。而 <strong>穩健擬合(robust fit)</strong> 是 underfitting 與 overfitting 之間的點，代表最佳的 epochs。
<img alt=robust_fit loading=lazy src=/ai/AI/5_1/robust_fit.png></li><li>下圖的黑線與就是 robust fit 的表現，綠線是 overfitting 的表現。<ul><li>可以看到綠線在訓練集有很好的表現，但可能會在新的資料點進入時，有錯誤的判斷。</li><li><strong>普適化</strong>就是找到一個面對所有資料都能有穩定且好的表現的模型。
<img alt=overfitting loading=lazy src=/ai/AI/5_1/overfitting.webp></li></ul></li></ul></li></ul><h3 id=overfitting>overfitting<a hidden class=anchor aria-hidden=true href=#overfitting>#</a></h3><ul><li>overfitting 容易發生在<ol><li>具有雜訊的資料</li><li>具有罕見特徵</li><li>標示錯誤的資料</li></ol><ul><li>如果訓練過程，模型針對這些離群值(outlier)進行學習，普適化表現自然會下降。</li></ul></li></ul><h3 id=模糊特徵>模糊特徵<a hidden class=anchor aria-hidden=true href=#模糊特徵>#</a></h3><ul><li>然後並非所有雜訊都是由不準確性(特徵模糊/標示錯誤)產生的，當處理的問題本身就具備不確定性或模棱兩可時，就算是字跡清晰、標籤正確也可能是雜訊，特別是一些沒有明確界線的特徵。</li></ul><blockquote><p>就像是下面的三杯一樣的水，由不同的人來 label，也會 label 出不一樣的答案。
<img alt=wafer loading=lazy src=/ai/AI/5_1/water.jpeg></p></blockquote><ul><li>最有感的就是問卷量表，客戶滿意度 (CSAT) 調查問卷通常分為 1 (非常不滿意) 到 5 分 (非常滿意) 。每個人對於滿意度的給分都不一致，所以就容易產生差異。</li><li>穩健的模型會忽略訓練資料中個別的資料點，從眾數著眼。</li></ul><h3 id=罕見特徵rare-feature與虛假關聯spurious-correlation>罕見特徵(rare feature)與虛假關聯(spurious correlation)<a hidden class=anchor aria-hidden=true href=#罕見特徵rare-feature與虛假關聯spurious-correlation>#</a></h3><ul><li><p><strong>罕見特徵</strong>: 通常是樣本中出現頻率極低的特徵，可能具有高辨識度或影響力，但也可能是噪音，需要小心解讀。</p><ol><li>事故發生的地點是某條高速公路上極少使用的臨時匝道。</li><li>事故發生時段是凌晨2點到3點，且伴隨濃霧天氣。</li><li>涉事車輛是一輛載有易燃化學品的大型貨車，並與一輛滿載乘客的大巴相撞。</li></ol><ul><li>如何影響機器學習：<ul><li>特徵稀疏性： 這些罕見的特徵組合在訓練數據中可能只出現過1-2次，但其後果卻極為嚴重（多人傷亡），模型可能過度強調這些罕見情況作為高危因素。</li><li>過擬合風險： 如果模型只根據這些少量案例進行學習，可能無法有效處理未見過的場景（如不同的道路或車輛組合）。</li></ul></li></ul></li><li><p><strong>虛假關聯</strong>: 則是數據之間表面上有相關性，但實際上缺乏因果關係，可能由於第三因素驅動或純粹的巧合。</p><ul><li>冰淇淋銷量與溺水事件：<ul><li>描述：夏季冰淇淋銷量與溺水事件呈現高度正相關。</li><li>原因：兩者都與溫度升高相關，並非冰淇淋銷量導致溺水事件增加。</li></ul></li></ul></li><li><p>接下來來做一個實驗，我們在每一張數字中擴充維度，分別擴充 noise 與 zeros
<img alt=noise_test loading=lazy src=/ai/AI/5_1/noise_test.png></p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> mnist
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(train_images, train_labels), (test_images, test_labels) <span style=color:#f92672>=</span> mnist<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>60000</span>, <span style=color:#ae81ff>28</span><span style=color:#f92672>*</span><span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#34;float32&#34;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_images_with_noise <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>concatenate(
</span></span><span style=display:flex><span>    [train_images, np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random((len(train_images), <span style=color:#ae81ff>784</span>))], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>train_images_with_zeros <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>concatenate(
</span></span><span style=display:flex><span>    [train_images, np<span style=color:#f92672>.</span>zeros((len(train_images), <span style=color:#ae81ff>784</span>))], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><ul><li>接著我們用這兩個資料集來進行 training，來觀察訓練後的結果：</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>build_model</span>():
</span></span><span style=display:flex><span>    model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>512</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;softmax&#34;</span>)
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>compile(
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;rmsprop&#34;</span>,
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sparse_categorical_crossentropy&#34;</span>,
</span></span><span style=display:flex><span>        metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;accuracy&#34;</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> model
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> build_model()
</span></span><span style=display:flex><span>history_noise <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(train_images_with_noise, train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>, validation_split<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>history_zeros <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(train_images_with_zeros, train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>, validation_split<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span></code></pre></div><ul><li>畫出損失曲線</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>val_acc_noise <span style=color:#f92672>=</span> history_noise<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#34;val_accuracy&#34;</span>]
</span></span><span style=display:flex><span>val_acc_zeros <span style=color:#f92672>=</span> history_zeros<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#34;val_accurarc&#34;</span>]
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> range(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>11</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_acc_noise, <span style=color:#e6db74>&#34;b-&#34;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;data with noise&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_acc_zeros, <span style=color:#e6db74>&#34;r-&#34;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;data with zeros&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Effect of noise channels on validtaion accuracy&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Epochs&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Validation accuracy&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span></code></pre></div><p><img alt=loss_curve loading=lazy src=/ai/AI/5_1/loss_curve.png></p><ul><li>可見兩組資料擁有相同的有效特徵資訊，但所訓練出來的模型在驗證準確度卻有明顯的差異，這差距來自於虛假關聯：但加入的雜訊愈多，準確度就會愈低。</li><li>雜訊幾乎都會造成 overfitting，故若不確定各種特徵是有用或無用時，通常要在訓練前進行特徵挑選(feature selection)。例如先前在 IMDB 資料，便時採用前 10000 個常用字。<ul><li>常用的方法還包括特量每個特徵對於任務關聯性的量測，如特徵與標籤之間的 MI(mutual information) 分數，只保留分數在一定門閾值以上的特徵，用以過濾雜訊。</li></ul></li></ul><h2 id=普適化的本質>普適化的本質<a hidden class=anchor aria-hidden=true href=#普適化的本質>#</a></h2><ul><li>事實上，只要模型具備足夠的學習能力，便可以持續訓練到能夠擬合任何的資料。</li><li>我們可以做一個實驗，將 mnist 的資料集的標籤打亂來進行訓練，此時圖片中的數字已與標籤無關聯，但訓練的失曲線仍會隨著訓練推進而持續下降。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> mnist
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>(train_images, train_labels), _ <span style=color:#f92672>=</span> mnist<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>60000</span>, <span style=color:#ae81ff>28</span><span style=color:#f92672>*</span><span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#34;float32&#34;</span>)<span style=color:#f92672>/</span><span style=color:#ae81ff>255</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>random_train_labels <span style=color:#f92672>=</span> train_labels[:]
</span></span><span style=display:flex><span>np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>shuffle(random_train_labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>512</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;softmax&#34;</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>,
</span></span><span style=display:flex><span>              loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sparse_categorical_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>              metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(train_images, random_train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>,validation_split<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> history<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#39;loss&#39;</span>]
</span></span><span style=display:flex><span>val_loss <span style=color:#f92672>=</span> history<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#39;val_loss&#39;</span>]
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> range(<span style=color:#ae81ff>1</span>, len(loss) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, loss, <span style=color:#e6db74>&#39;bo&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Training loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_loss, <span style=color:#e6db74>&#39;b&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Validation loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Training and validation loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Epochs&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img alt=random_label_test loading=lazy src=/ai/AI/5_1/random_label_test.png></p><ul><li>代表只要訓練次數夠多，終究能擬合訓練資料，就像是 dictionary 一樣，輸入與標籤就猶如字典的 key 與 value 一樣。</li></ul><h3 id=流形假說manifold-hypothesis>流形假說(manifold hypothesis)<a hidden class=anchor aria-hidden=true href=#流形假說manifold-hypothesis>#</a></h3><ul><li>真實世界的高維數據通常位於低維流形(manifold)上，這些數據點雖然存在於高維空間，但實際上具有更低的內在維度。</li><li>以 MNIST 為例，雖然每張圖片是 28×28=784 維的數據，但實際上所有手寫數字圖片大致分布在一個低維流形上</li><li>簡單想像你在玩一個猜拳的遊戲(剪刀、石頭、布)：<ul><li>高維空間的概念<ul><li>如果你用相機拍下出拳的手勢，每張照片可能是 1000×1000 像素，這代表每張照片在數學上是個 100 萬維的數據點，但實際上，手勢只有剪刀、石頭、布三種可能。</li></ul></li><li>流形的概念<ul><li>雖然照片是高維的，但手勢的變化是有限的，你可以慢慢從剪刀變成石頭，手指會沿著某個固定的軌跡彎曲，這個軌跡就像是一條"路徑"，這就是所謂的流形。</li></ul></li></ul></li></ul><details><summary>流形概念例子</summary><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> mnist
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入 MNIST 數據</span>
</span></span><span style=display:flex><span>(x_train, y_train), _ <span style=color:#f92672>=</span> mnist<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> x_train<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;float32&#39;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 找出數字 1 和 7 的例子</span>
</span></span><span style=display:flex><span>digit_1 <span style=color:#f92672>=</span> x_train[y_train <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>][<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>digit_7 <span style=color:#f92672>=</span> x_train[y_train <span style=color:#f92672>==</span> <span style=color:#ae81ff>7</span>][<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 創建中間過渡圖片</span>
</span></span><span style=display:flex><span>steps <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>transitions <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(steps):
</span></span><span style=display:flex><span>    alpha <span style=color:#f92672>=</span> i <span style=color:#f92672>/</span> (steps<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 簡單的線性混合</span>
</span></span><span style=display:flex><span>    mixed <span style=color:#f92672>=</span> digit_1 <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>alpha) <span style=color:#f92672>+</span> digit_7 <span style=color:#f92672>*</span> alpha
</span></span><span style=display:flex><span>    transitions<span style=color:#f92672>.</span>append(mixed)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 顯示結果</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(steps):
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, steps, i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>imshow(transitions[i], cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>suptitle(<span style=color:#e6db74>&#39;transition of number 1 to 7&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img alt=manifold loading=lazy src=/ai/AI/5_1/manifold.png></details></p><h3 id=以內插法作為普適化的基礎>以內插法作為普適化的基礎<a hidden class=anchor aria-hidden=true href=#以內插法作為普適化的基礎>#</a></h3><ul><li>深度學習的普適化能力，很大程度上依賴於模型能夠在訓練數據的流形上進行合理的內插。讓我們通過實驗來比較<strong>流形內插</strong>和<strong>線性內插</strong>的差異：
<img alt=interpolation loading=lazy src=/ai/AI/5_1/interpolation.png></li></ul><details><summary>內插法程式</summary><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> mnist
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入 MNIST 數據集</span>
</span></span><span style=display:flex><span>(x_train, y_train), _ <span style=color:#f92672>=</span> mnist<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> x_train<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;float32&#39;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255.</span>
</span></span><span style=display:flex><span>x_train_reshaped <span style=color:#f92672>=</span> x_train<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立編碼器</span>
</span></span><span style=display:flex><span>encoder_input <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Input(shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Flatten()(encoder_input)
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>128</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>latent <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>32</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>encoder <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Model(encoder_input, latent, name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;encoder&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立解碼器</span>
</span></span><span style=display:flex><span>decoder_input <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Input(shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>32</span>,))
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)(decoder_input)
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>128</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>784</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sigmoid&#39;</span>)(x)
</span></span><span style=display:flex><span>decoder_output <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Reshape((<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>1</span>))(x)
</span></span><span style=display:flex><span>decoder <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Model(decoder_input, decoder_output, name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;decoder&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 建立完整的自編碼器</span>
</span></span><span style=display:flex><span>autoencoder_input <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Input(shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>encoded <span style=color:#f92672>=</span> encoder(autoencoder_input)
</span></span><span style=display:flex><span>decoded <span style=color:#f92672>=</span> decoder(encoded)
</span></span><span style=display:flex><span>autoencoder <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Model(autoencoder_input, decoded, name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;autoencoder&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 編譯和訓練</span>
</span></span><span style=display:flex><span>autoencoder<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>, loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;binary_crossentropy&#39;</span>)
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> autoencoder<span style=color:#f92672>.</span>fit(x_train_reshaped, x_train_reshaped,
</span></span><span style=display:flex><span>                         epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>,
</span></span><span style=display:flex><span>                         batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>256</span>,
</span></span><span style=display:flex><span>                         shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>                         validation_split<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 選擇兩張不同的數字圖片</span>
</span></span><span style=display:flex><span>img1 <span style=color:#f92672>=</span> x_train_reshaped[y_train <span style=color:#f92672>==</span> <span style=color:#ae81ff>2</span>][<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>1</span>]  <span style=color:#75715e># 選擇一個 2</span>
</span></span><span style=display:flex><span>img2 <span style=color:#f92672>=</span> x_train_reshaped[y_train <span style=color:#f92672>==</span> <span style=color:#ae81ff>7</span>][<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>1</span>]  <span style=color:#75715e># 選擇一個 7</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 生成線性內插</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>linear_interpolation</span>(img1, img2, num_steps<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    alphas <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, num_steps)
</span></span><span style=display:flex><span>    images <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> alpha <span style=color:#f92672>in</span> alphas:
</span></span><span style=display:flex><span>        interpolated <span style=color:#f92672>=</span> img1 <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> alpha) <span style=color:#f92672>+</span> img2 <span style=color:#f92672>*</span> alpha
</span></span><span style=display:flex><span>        images<span style=color:#f92672>.</span>append(interpolated[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>array(images)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 生成流形內插</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>manifold_interpolation</span>(img1, img2, num_steps<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 獲取潛在表示</span>
</span></span><span style=display:flex><span>    latent1 <span style=color:#f92672>=</span> encoder<span style=color:#f92672>.</span>predict(img1)
</span></span><span style=display:flex><span>    latent2 <span style=color:#f92672>=</span> encoder<span style=color:#f92672>.</span>predict(img2)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 在潛在空間中內插</span>
</span></span><span style=display:flex><span>    alphas <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, num_steps)
</span></span><span style=display:flex><span>    images <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> alpha <span style=color:#f92672>in</span> alphas:
</span></span><span style=display:flex><span>        interpolated_latent <span style=color:#f92672>=</span> latent1 <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> alpha) <span style=color:#f92672>+</span> latent2 <span style=color:#f92672>*</span> alpha
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用解碼器重建圖片</span>
</span></span><span style=display:flex><span>        decoded_img <span style=color:#f92672>=</span> decoder<span style=color:#f92672>.</span>predict(interpolated_latent)
</span></span><span style=display:flex><span>        images<span style=color:#f92672>.</span>append(decoded_img[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>array(images)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 生成內插序列</span>
</span></span><span style=display:flex><span>linear_imgs <span style=color:#f92672>=</span> linear_interpolation(img1, img2)
</span></span><span style=display:flex><span>manifold_imgs <span style=color:#f92672>=</span> manifold_interpolation(img1, img2)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 顯示結果</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 顯示線性內插</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;linear interpolation&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>, i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>imshow(linear_imgs[i]<span style=color:#f92672>.</span>reshape(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 顯示流形內插</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;manifold interpolation&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>, i <span style=color:#f92672>+</span> <span style=color:#ae81ff>6</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>imshow(manifold_imgs[i]<span style=color:#f92672>.</span>reshape(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div></details><ul><li>換言之，因為新的資料可以透過現有的資料點內插而得，代表我們可以將新資料點連結到流形上相近的其它點，進而理解這些從未見過的資料點。也就是說我們可以靠空間的有限樣本來理解空間的整體性，做法是透過內插法來填滿其中的空白。以下是我的想像示意圖。
<img alt=imagine loading=lazy src=/ai/AI/5_1/imagine.png></li></ul><h3 id=為何深度學習能運作>為何深度學習能運作<a hidden class=anchor aria-hidden=true href=#為何深度學習能運作>#</a></h3><ul><li><p>流形假說幫助我們理解為什麼深度學習能夠有效運作：</p><ol><li>流形學習：深度學習模型通過多層結構，逐漸學習數據的內在流形結構。</li><li>維度降低：神經網絡的中間層實際上在執行非線性維度降低，將高維輸入映射到更有意義的低維表示。</li><li>連續變化：在流形上的內插產生的是連續、平滑的變化，而不是簡單的線性混合：<ul><li>線性內插：直接在像素空間中進行混合，可能產生不自然的中間狀態</li><li>流形內插：在學習到的流形空間中進行內插，產生的中間狀態更符合實際數據分布</li></ul></li><li>歸納能力：模型的普適化能力很大程度上來自於它能夠在流形上進行合理的內插，而不是簡單地記住訓練數據。</li></ol></li><li><p>這個實驗展示了為什麼簡單的線性內插會產生模糊或不自然的結果，而流形內插能產生更真實的過渡狀態。這也說明了深度學習模型不僅僅是在記憶數據，而是真正學習到了數據的內在結構。</p></li></ul><h3 id=訓練資料的處理>訓練資料的處理<a hidden class=anchor aria-hidden=true href=#訓練資料的處理>#</a></h3><ul><li><p>儘管深度學習適合流形學習(manifold learning)，但普適化能力主要還是取決於資料的自然結構，而非模型的特性。只有當資料流形中的點可以內插，才有可能進行普適化。資料中的特徵愈清晰、愈沒有雜訊，普適化的能力才會愈好。這是因為輸入空間變得更簡單且有著更好的結構。</p></li><li><p>故如果要提升普適化表現，資料篩選(data curation)和特徵工程(feature engineering)就尤為重要。</p></li><li><p>以下同樣也是我的想像示意圖
<img alt=screening loading=lazy src=/ai/AI/5_1/screening.png></p></li><li><p>模型若要表現良好，最好可以在輸入空間中密集抽樣(dense sampling)，並用抽樣出的資料來訓練模型。所謂密集抽樣是指訓練資料應該密集地涵蓋整個輸入空間的流形附近，特別是<strong>決策邊界</strong>附近
<img alt=dense_sampling loading=lazy src=/ai/AI/5_1/dense_sampling.png></p></li><li><p>若想要模型表示得好，就得提供更多或更多的資料，那麼輸入資料的流形可以覆蓋更多、更密集的範圍，使得普適化能力更好。由於模型只能單純地在訓練樣本間進行內插，因此我們要讓模型可以透過簡單正確地內插，這一切將取決於模型的設計架構與訓練的資料。</p></li><li><p>當無法取得更多資料時，我們能做的就是調降模型所能容納的資訊，或是在模型的擬合曲線上加入一些限制。讓模型只能記憶很有限或常見的樣態，在優化過程中強迫模型專注於最突出的樣態，這樣就有可能提升普適化能力。這種避免 overfitting 的方法叫作<strong>常規化(regularization)</strong>
<img alt=regularization loading=lazy src=/ai/AI/5_1/regularization.png></p></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://intervalrain.github.io/tags/ai/>AI</a></li></ul><nav class=paginav><a class=prev href=https://intervalrain.github.io/ai/4_3/><span class=title>« 上一頁</span><br><span>[AI] 迴歸問題</span>
</a><a class=next href=https://intervalrain.github.io/ai/5_2/><span class=title>下一頁 »</span><br><span>[AI] 評估模型</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Reid00/hugo-blog-talks issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://intervalrain.github.io/>Rain Hu's Workspace</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="複製";function s(){t.innerHTML="已複製！",setTimeout(()=>{t.innerHTML="複製"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>