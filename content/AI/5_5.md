---
title: "[AI] 機器學習的流程"
date: 2025-01-12T17:54:31+08:00
tags: ["AI"]
description: "The flow of machine learning"
author: "Rain Hu"
showToc: true
TocOpen: true
math: true
hidemeta: false
canonicalURL: "https://intervalrain.github.io/"
disableHLJS: true
disableShare: true
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowCodeCopyButtons: true
---

# 機器學器的工作流程
+ 一般而言，機器學習的通用工作流程可以歸納為三個部分: 
    1. 定義任務(Define the task): 瞭解需求背後的問題領域與業務邏輯、收集資料、瞭解資料內容，並選擇衡量任務成功的標準。
    2. 開發模型(Develop a model): 準備好模型可以處理的資料、定義基準線、先訓練出一個能 overfitting 的模型，最後進行常規化、調整模型以提高普適化表現。
    3. 部署模型(Deploy a model): 將模型部署至伺服器、app、網頁或嵌入式裝置，並監控模型表現。

## 定義任務
+ 問題域
    + 輸入資料: 我們需要知道輸入資料是什麼
    + 目標: 我們要知道想要預測什麼

+ 任務類型
    + 我們要定義我的的任務是哪種類型: 
        + 二元分類任務
        + 多類別分類任務
        + 純量迴歸
        + 向量迴歸
        + 多類別且多標籤任務
        + 影像分割任務
        + 排序任務
        + 資料分群分任
        + 生成任務
        + 強式化學習任務
        + ...
    + 並不一定所有的任務類型都適用機器學習，傳統的統計分析方法也許更有效。

+ 參考現有的解決方案
    + 我們必須先瞭解當前的解決方案是怎麼運作。

+ 限制條件
    + 模型是在伺服器運作嗎？或是因為端到到加密，模型需在裝置上運行，並使用外部資料訓練。

+ 資料的充足性
    + 我們想要預測的資料是否可以透過輸入來預測。
        + 舉例來說我們想要預測未來股價，但是我們只有該股的歷史股價，則不具備資料充足性，應該要加入如 eps 等其它表徵資料。

+ **建立資料集**
+ 資料甚至比演算法還重要(The Unreasonable Effectiveness of Data)
    + 投資在資料標註工具
        + 自行標註
        + 外包平台，如 Mechanical Turk
        + 專業資料標註公司
        + 注意：需考慮資料標註是否需要領域專家
    + 留意不具代表性的資料: 資料一定要足以代表實際運作的資料
        + 即我們的訓練資料要可以表達實際運用的場景。可以參考抽樣偏差(sampling bias)
        + 概念漂移: 資料具有時間性，2020 年訓練出來的模型，無法描述 2025 年發生的事。
    + 理解資料
        + 先從資料中抽幾個樣本與標籤，對資料進行解讀。
        + 對資料有些概觀性的瞭解，判斷是否缺少特徵值、瞭解資料的 pattern。
        + 檢查是否存在目標值洩漏(target leaking) 的問題。
    + 選擇測量成效的方法
        + 考慮準確度(accuracy)、精準度(precision)、故障召回率(recall)、客戶回流率?
        + 好的評量指標(metric) 會引導專案的所有技術選擇，盡可能要與更高層次的目標保持一致。
        + ROC(receiveer operating characteristic) 曲線下面積 (ROC AUC, ROC Area Under Curve)

## 開發模型
+ 準備資料
    + 通常模型無法接受原始資料，需經過預處理。
        + 向量化(vectorization)
        + 正規化(normalization)
        + 處理缺失值

+ 選擇驗證機制
    + 拆分驗證集(holdout validation set)
    + K-fold
    + Iterated K-fold

+ 超越基準線
    + 特徵工程
    + 選擇架構
    + 決定訓練配置
    $$
    \begin{array}{|c|c|c|}
        \text{問題類型}&\text{輸出層激活函數}&\text{損失函數}\\\\\hline
        \text{二元分類}&\text{sigmoid}&\text{binary crossentropy}\\\\
        \text{多類別、單標籤分類}&\text{softmax}&\text{categorical crossentropy}\\\\
        \text{多類別、多標籤分類}&\text{sigmoid}&\text{binary crossentropy}
    \end{array}
    $$

+ 擴大規模: 開發一個會 overfitting 的模型
    + 添加更多神經層
    + 選擇更寬的神經層
    + 訓練更多週期(epoch)

+ 將模型常規化並調整超參數
    + 嘗試不同架構
    + dropout
    + L1, L2 常規化(當模型不大)
    + 嘗試不同超參數(ex. 優化器策略)
    + 資料篩選、特徵工程

## 部署模型
+ 向客戶說明成果、建立合理期待
    + 清楚說明模型的能力與限制
    + 提供模型在不同場景下的表現數據
    + 說明可能的錯誤類型與處理方式
    + 建立明確的效能指標與監控機制

+ 交付模型
    + REST API 部署
        + 建立可擴展的API架構
        + 實作請求限制與認證機制
        + 考慮負載平衡策略
    + 裝置上部署
        + 考慮記憶體與運算資源限制
        + 進行模型優化
            + 權重修剪(weight pruning)移除不重要的連接
            + 權重量化(weight quantization)降低數值精度
        + 整合至原生應用程式
    + 瀏覽器部署
        + 使用 TensorFlow.js 等前端架構
        + 優化模型大小與載入時間
        + 處理跨瀏覽器相容性

+ 監控模型運作
    + 實施 A/B 測試
        + 比較不同版本模型的表現
        + 收集使用者行為數據
        + 評估新功能的效果
    + 收集使用者回饋
        + 建立回饋機制
        + 分析錯誤案例
        + 持續改善模型表現
    + 監控模型效能
        + 追蹤關鍵指標變化
        + 設定警示機制
        + 分析效能瓶頸

+ 維護模型
    + 關注新特徵
        + 評估新資料源的價值
        + 驗證特徵的穩定性
        + 更新特徵工程流程
    + 處理概念漂移
        + 定期重新訓練模型
        + 監控資料分布變化
        + 更新評估指標
    + 版本管理
        + 維護模型版本紀錄
        + 建立回滾機制
        + 文件化更新流程